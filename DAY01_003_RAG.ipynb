{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f191d1cf",
   "metadata": {},
   "source": [
    "#  RAG 체인 구성\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641ec21",
   "metadata": {},
   "source": [
    "## RAG란 무엇인가?\n",
    "\n",
    "### 🎯 핵심 개념\n",
    "**Retrieval Augmented Generation (RAG)** 는 대규모 언어 모델(LLM)에 외부 지식을 연결하여 더 정확하고 최신의 정보를 제공하는 AI 프레임워크입니다.\n",
    "\n",
    "### 🔍 RAG의 작동 원리\n",
    "```\n",
    "사용자 질문 → 관련 문서 검색 → 컨텍스트와 함께 LLM에 전달 → 답변 생성\n",
    "```\n",
    "\n",
    "### 📊 RAG vs 일반 LLM 비교\n",
    "| 구분 | 일반 LLM | RAG |\n",
    "|------|----------|-----|\n",
    "| 정보 소스 | 사전 훈련 데이터만 | 외부 지식베이스 + 사전 훈련 데이터 |\n",
    "| 최신성 | 훈련 시점까지 | 실시간 업데이트 가능 |\n",
    "| 정확성 | 환각(hallucination) 가능성 | 검증된 문서 기반 답변 |\n",
    "| 사용 사례 | 일반적인 질문 답변 | 특정 도메인의 전문적 답변 |\n",
    "\n",
    "---\n",
    "\n",
    "## 환경 설정\n",
    "\n",
    "### 🛠️ 필수 라이브러리 설치\n",
    "\n",
    "```bash\n",
    "# 기본 LangChain 패키지\n",
    "pip install langchain langchain-community \n",
    "\n",
    "# 임베딩 모델\n",
    "pip install langchain-openai langchain-huggingface\n",
    "\n",
    "# 벡터 저장소\n",
    "pip install langchain-chroma\n",
    "\n",
    "# 문서 처리\n",
    "pip install pypdf \n",
    "\n",
    "# 웹 스크래핑\n",
    "pip install beautifulsoup4\n",
    "\n",
    "# 토크나이저\n",
    "pip install tiktoken transformers sentence-transformers\n",
    "\n",
    "# 실험적 기능 (SemanticChunker)\n",
    "pip install langchain-experimental\n",
    "\n",
    "\n",
    "uv add langchain_community\n",
    "uv add pypdf  \n",
    "uv add bs4  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be5eb8",
   "metadata": {},
   "source": [
    "### 🔑 환경 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829d8712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .env 파일 생성\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API 키 설정 (필요시)\n",
    "# OPENAI_API_KEY=your_openai_api_key_here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5989430",
   "metadata": {},
   "source": [
    "### 📋 기본 라이브러리 import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa02fc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c23a89",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 문서 로더 (Document Loaders)\n",
    "\n",
    "### 🎯 문서 로더란?\n",
    "**Document Loader**는 다양한 소스에서 문서를 로드하여 LangChain의 `Document` 객체로 변환하는 도구입니다.\n",
    "\n",
    "### 📄 Document 객체 구조\n",
    "```python\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Document 객체의 기본 구조\n",
    "document = Document(\n",
    "    page_content=\"문서의 텍스트 내용\",\n",
    "    metadata={\n",
    "        \"source\": \"문서 출처\",\n",
    "        \"page\": 1,\n",
    "        \"title\": \"문서 제목\"\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "### 📄 문서 로더의 종류\n",
    "- PDF 파일 로더\n",
    "- 웹 페이지 로더 \n",
    "- CSV 데이터 로더\n",
    "- 디렉토리 로더\n",
    "- HTML 데이터 로더\n",
    "- JSON 데이터 로더\n",
    "- Markdown 데이터 로더\n",
    "- Microsoft Office 데이터 로더\n",
    "\n",
    "\n",
    "### 1. 🌐 웹 문서 로더 (WebBaseLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c00ab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 문서 수: 2\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "# 기본 웹 문서 로드\n",
    "web_loader = WebBaseLoader(\n",
    "    web_paths=[\n",
    "        \"https://python.langchain.com/docs/tutorials/rag/\",\n",
    "        \"https://js.langchain.com/docs/tutorials/rag/\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 문서 로드\n",
    "web_docs = web_loader.load()\n",
    "print(f\"로드된 문서 수: {len(web_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67940f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 문서 내용:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Build a Retrieval Augmented Generation (RAG) App: Part 1 | 🦜️🔗 LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a ...\n"
     ]
    }
   ],
   "source": [
    "print(f\"첫 번째 문서 내용:\\n{web_docs[0].page_content[:1500]}...\")  # 앞부분만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aab86e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 문서 메타데이터: {'source': 'https://python.langchain.com/docs/tutorials/rag/', 'title': 'Build a Retrieval Augmented Generation (RAG) App: Part 1 | 🦜️🔗 LangChain', 'description': 'One of the most powerful applications enabled by LLMs is sophisticated question-answering (Q&A) chatbots. These are applications that can answer questions about specific source information. These applications use a technique known as Retrieval Augmented Generation, or RAG.', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"첫 번째 문서 메타데이터: {web_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e239cbc0",
   "metadata": {},
   "source": [
    "### 2. 📊 CSV 파일 로더 (CSVLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ee6c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 수: 10\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# 기본 CSV 로드\n",
    "csv_loader = CSVLoader(\"./data/kbo_teams_2023.csv\", encoding=\"utf-8\")\n",
    "csv_docs = csv_loader.load()\n",
    "\n",
    "print(f\"문서 수: {len(csv_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41430baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 문서 내용:\n",
      "Team: KIA 타이거즈\n",
      "City: 광주\n",
      "Founded: 1982\n",
      "Home Stadium: 광주-기아 챔피언스 필드\n",
      "Championships: 11\n",
      "Introduction: KBO 리그의 전통 강호로, 역대 최다 우승 기록을 보유하고 있다. '타이거즈 스피릿'으로 유명하며, 양현종, 안치홍 등 스타 선수들을 배출했다. 광주를 연고로 하는 유일한 프로야구팀으로 지역 사랑이 강하다.\n"
     ]
    }
   ],
   "source": [
    "print(f\"첫 번째 문서 내용:\\n{csv_docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a2ed938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 문서 메타데이터: {'source': './data/kbo_teams_2023.csv', 'row': 0}\n"
     ]
    }
   ],
   "source": [
    "print(f\"첫 번째 문서 메타데이터: {csv_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68d1fa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 수: 10\n"
     ]
    }
   ],
   "source": [
    "# 소스 컬럼 지정 및 인코딩 설정\n",
    "csv_loader_advanced = CSVLoader(\n",
    "    file_path=\"./data/kbo_teams_2023.csv\",\n",
    "    source_column=\"Team\",      # 이 컬럼이 메타데이터의 source가 됨\n",
    "    content_columns=[\"Team\", \"Introduction\"],  # 이 컬럼이 문서의 내용이 됨\n",
    "    metadata_columns=[\"Founded\", \"City\"],  # 이 컬럼이 메타데이터에 추가됨\n",
    "    encoding=\"utf-8\",          # 인코딩 명시\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",      # 구분자\n",
    "        \"quotechar\": '\"',      # 인용 문자\n",
    "    }\n",
    ")\n",
    "\n",
    "csv_docs_advanced = csv_loader_advanced.load()\n",
    "\n",
    "# 문서 수와 첫 번째 문서 내용 출력\n",
    "print(f\"문서 수: {len(csv_docs_advanced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86b02841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마지막 문서 내용:\n",
      "Team: 한화 이글스\n",
      "Introduction: 대전을 연고로 하는 구단으로, 1999년 한국시리즈 우승을 차지했다. '절친 야구'로 유명한 정근우, 이용규 등의 선수들이 팀을 대표했다. 최근 몇 년간 성적이 부진했지만, 젊은 선수들의 육성에 힘쓰며 재건을 꾀하고 있다.\n"
     ]
    }
   ],
   "source": [
    "print(f\"마지막 문서 내용:\\n{csv_docs_advanced[-1].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fb2c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마지막 문서 메타데이터: {'source': '한화 이글스', 'row': 9, 'Founded': '1986', 'City': '대전'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"마지막 문서 메타데이터: {csv_docs_advanced[-1].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e9558",
   "metadata": {},
   "source": [
    "### 3. 📖 PDF 파일 로더 \n",
    "\n",
    "- **PyPDFLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d82df94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 문서 개수: 20\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 로더 초기화\n",
    "pdf_loader = PyPDFLoader('./data/labor_law.pdf')\n",
    "\n",
    "# 동기 로딩\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6939bfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페이지 1: 1811 문자\n",
      "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2024-10-15T14:45:34+09:00', 'moddate': '2024-10-15T14:45:34+09:00', 'source': './data/labor_law.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}\n",
      "페이지 2: 1709 문자\n",
      "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2024-10-15T14:45:34+09:00', 'moddate': '2024-10-15T14:45:34+09:00', 'source': './data/labor_law.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2'}\n",
      "페이지 3: 2164 문자\n",
      "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PyPDF', 'creationdate': '2024-10-15T14:45:34+09:00', 'moddate': '2024-10-15T14:45:34+09:00', 'source': './data/labor_law.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3'}\n"
     ]
    }
   ],
   "source": [
    "# 각 페이지별 정보 확인\n",
    "for i, doc in enumerate(pdf_docs[:3]):\n",
    "    print(f\"페이지 {i+1}: {len(doc.page_content)} 문자\")\n",
    "    print(f\"메타데이터: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e68eaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "법제처                                                            1                                                       국가법령정보센터\n",
      "근로기준법\n",
      " \n",
      "근로기준법\n",
      "[시행 2021. 11. 19.] [법률 제18176호, 2021. 5. 18., 일부개정]\n",
      "고용노동부 (근로기준정책과 - 해고, 취업규칙, 기타) 044-202-7534\n",
      "고용노동부 (근로기준정책과 - 소년) 044-202-7535\n",
      "고용노동부 (근로기준정책과 - 임금) 044-202-7548\n",
      "고용노동부 (여성고용정책과 - 여성) 044-202-7475\n",
      "고용노동부 (임금근로시간정책과 - 근로시간, 휴게) 044-202-7545\n",
      "고용노동부 (임금근로시간정책과 - 휴일, 연차휴가) 044-202-7973\n",
      "고용노동부 (임금근로시간정책과 - 제63조 적용제외, 특례업종) 044-202-7530\n",
      "고용노동부 (임금근로시간정책과 - 유연근로시간제) 044-202-7549\n",
      "       제1장 총칙\n",
      " \n",
      "제1조(목적) 이 법은 헌법에 따라 근로조건의 기준을 정함으로써 근로자의 기본적 생활을 보장, 향상시키며 균형 있는\n",
      "국민경제의 발전을 꾀하는 것을 목적으로 한다.\n",
      " \n",
      "제2조(정의) ① 이 법에서 사용하는 용어의 뜻은 다음과 같다. <개정 2018. 3. 20., 2019. 1. 15., 2020. 5. 26.>\n",
      "1. “근로자”란 직업의 종류와 관계없이 임금을 목적으로 사업이나 사업장에 근로를 제공하는 사람을 말한다.\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "말한다.\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n",
      "5. “임금”이란 사용자가 근로의 대가로 근로자에게 임금, 봉급, 그 밖에 어떠한 명칭으로든지 지급하는 모든 금품\n"
     ]
    }
   ],
   "source": [
    "print(pdf_docs[0].page_content[:1000])  # 첫 페이지의 내용 일부 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c964d1",
   "metadata": {},
   "source": [
    "- **다른 PDF 로더들**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a60f3128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import (\n",
    "    PyMuPDFLoader,\n",
    "    PDFMinerLoader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28116083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 문서 개수: 20\n",
      "페이지 1: 1811 문자\n",
      "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': '', 'creationdate': '2024-10-15T14:45:34+09:00', 'source': './data/labor_law.pdf', 'file_path': './data/labor_law.pdf', 'total_pages': 20, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-10-15T14:45:34+09:00', 'trapped': '', 'modDate': \"D:20241015144534+09'00'\", 'creationDate': \"D:20241015144534+09'00'\", 'page': 0}\n",
      "페이지 2: 1709 문자\n",
      "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': '', 'creationdate': '2024-10-15T14:45:34+09:00', 'source': './data/labor_law.pdf', 'file_path': './data/labor_law.pdf', 'total_pages': 20, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-10-15T14:45:34+09:00', 'trapped': '', 'modDate': \"D:20241015144534+09'00'\", 'creationDate': \"D:20241015144534+09'00'\", 'page': 1}\n",
      "페이지 3: 2164 문자\n",
      "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': '', 'creationdate': '2024-10-15T14:45:34+09:00', 'source': './data/labor_law.pdf', 'file_path': './data/labor_law.pdf', 'total_pages': 20, 'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-10-15T14:45:34+09:00', 'trapped': '', 'modDate': \"D:20241015144534+09'00'\", 'creationDate': \"D:20241015144534+09'00'\", 'page': 2}\n"
     ]
    }
   ],
   "source": [
    "# PyMuPDF 로더 (빠른 처리)\n",
    "pymupdf_loader = PyMuPDFLoader(\"./data/labor_law.pdf\")\n",
    "pdf_docs = pymupdf_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')\n",
    "\n",
    "# 각 페이지별 정보 확인\n",
    "for i, doc in enumerate(pdf_docs[:3]):\n",
    "    print(f\"페이지 {i+1}: {len(doc.page_content)} 문자\")\n",
    "    print(f\"메타데이터: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d660549a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "법제처                                                            1                                                       국가법령정보센터\n",
      "근로기준법\n",
      " \n",
      "근로기준법\n",
      "[시행 2021. 11. 19.] [법률 제18176호, 2021. 5. 18., 일부개정]\n",
      "고용노동부 (근로기준정책과 - 해고, 취업규칙, 기타) 044-202-7534\n",
      "고용노동부 (근로기준정책과 - 소년) 044-202-7535\n",
      "고용노동부 (근로기준정책과 - 임금) 044-202-7548\n",
      "고용노동부 (여성고용정책과 - 여성) 044-202-7475\n",
      "고용노동부 (임금근로시간정책과 - 근로시간, 휴게) 044-202-7545\n",
      "고용노동부 (임금근로시간정책과 - 휴일, 연차휴가) 044-202-7973\n",
      "고용노동부 (임금근로시간정책과 - 제63조 적용제외, 특례업종) 044-202-7530\n",
      "고용노동부 (임금근로시간정책과 - 유연근로시간제) 044-202-7549\n",
      "       제1장 총칙\n",
      " \n",
      "제1조(목적) 이 법은 헌법에 따라 근로조건의 기준을 정함으로써 근로자의 기본적 생활을 보장, 향상시키며 균형 있는\n",
      "국민경제의 발전을 꾀하는 것을 목적으로 한다.\n",
      " \n",
      "제2조(정의) ① 이 법에서 사용하는 용어의 뜻은 다음과 같다. <개정 2018. 3. 20., 2019. 1. 15., 2020. 5. 26.>\n",
      "1. “근로자”란 직업의 종류와 관계없이 임금을 목적으로 사업이나 사업장에 근로를 제공하는 사람을 말한다.\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "말한다.\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n",
      "5. “임금”이란 사용자가 근로의 대가로 근로자에게 임금, 봉급, 그 밖에 어떠한 명칭으로든지 지급하는 모든 금품\n"
     ]
    }
   ],
   "source": [
    "print(pdf_docs[0].page_content[:1000])  # 첫 페이지의 내용 일부 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90aa754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 문서 개수: 1\n",
      "페이지 1: 40085 문자\n",
      "메타데이터: {'producer': 'iText 2.1.7 by 1T3XT', 'creator': 'PDFMiner', 'creationdate': '2024-10-15T14:45:34+09:00', 'moddate': '2024-10-15T14:45:34+09:00', 'total_pages': 20, 'source': './data/labor_law.pdf'}\n"
     ]
    }
   ],
   "source": [
    "# PDFMiner 로더 (정확한 텍스트 추출)\n",
    "pdfminer_loader = PDFMinerLoader(\"./data/labor_law.pdf\")\n",
    "pdf_docs = pdfminer_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')\n",
    "\n",
    "# 각 페이지별 정보 확인\n",
    "for i, doc in enumerate(pdf_docs[:3]):\n",
    "    print(f\"페이지 {i+1}: {len(doc.page_content)} 문자\")\n",
    "    print(f\"메타데이터: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f249b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "근로기준법\n",
      "\n",
      "근로기준법\n",
      "\n",
      "[시행 2021. 11. 19.] [법률 제18176호, 2021. 5. 18., 일부개정]\n",
      "\n",
      "고용노동부 (근로기준정책과 - 해고, 취업규칙, 기타) 044-202-7534\n",
      "\n",
      "고용노동부 (근로기준정책과 - 소년) 044-202-7535\n",
      "\n",
      "고용노동부 (근로기준정책과 - 임금) 044-202-7548\n",
      "\n",
      "고용노동부 (여성고용정책과 - 여성) 044-202-7475\n",
      "\n",
      "고용노동부 (임금근로시간정책과 - 근로시간, 휴게) 044-202-7545\n",
      "\n",
      "고용노동부 (임금근로시간정책과 - 휴일, 연차휴가) 044-202-7973\n",
      "\n",
      "고용노동부 (임금근로시간정책과 - 제63조 적용제외, 특례업종) 044-202-7530\n",
      "\n",
      "고용노동부 (임금근로시간정책과 - 유연근로시간제) 044-202-7549\n",
      "\n",
      "       제1장 총칙\n",
      "\n",
      "제1조(목적) 이 법은 헌법에 따라 근로조건의 기준을 정함으로써 근로자의 기본적 생활을 보장, 향상시키며 균형 있는\n",
      "\n",
      "국민경제의 발전을 꾀하는 것을 목적으로 한다.\n",
      "\n",
      "제2조(정의) ① 이 법에서 사용하는 용어의 뜻은 다음과 같다. <개정 2018. 3. 20., 2019. 1. 15., 2020. 5. 26.>\n",
      "\n",
      "1. “근로자”란 직업의 종류와 관계없이 임금을 목적으로 사업이나 사업장에 근로를 제공하는 사람을 말한다.\n",
      "\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "\n",
      "말한다.\n",
      "\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "\n",
      "결된 계약을 말한다.\n",
      "\n",
      "5. “임금”이란 사용자가 근로의 대가로 근로자에게 임금, 봉급, 그 밖에 어떠한 명칭으로든지 지급하는 모든 금품을\n",
      "\n",
      "말한다.\n",
      "\n",
      "6. “평균임금”이란 이를 산정하여야 할 사유가 발생한 날 이전 3개월 동안에 그 근로자에게 지급된 임금의 총액을\n",
      "\n",
      "그 기간의 총일수로 나눈 금액을 말한다. 근로자가 취업한 후 3개월 미\n"
     ]
    }
   ],
   "source": [
    "print(pdf_docs[0].page_content[:1000])  # 첫 페이지의 내용 일부 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2907759c",
   "metadata": {},
   "source": [
    "### 4. 📝 텍스트 파일 로더 (TextLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60e731e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 수: 1\n",
      "첫 번째 문서 내용:\n",
      "1. 시그니처 스테이크\n",
      "   • 가격: ₩35,000\n",
      "   • 주요 식재료: 최상급 한우 등심, 로즈메리 감자, 그릴드 아스파라거스\n",
      "   • 설명: 셰프의 특제 시그니처 메뉴로, 21일간 건조 숙성한 최상급 한우 등심을 사용합니다. 미디엄 레어로 조리하여 육즙을 최대한 보존하며, 로즈메리 향의 감자와 아삭한 그릴드 아스파라거스가 곁들여집니다. 레드와인 소스와 함께 제공되어 풍부한 맛을 더합니다.\n",
      "\n",
      "2. 트러플 리조또\n",
      "   • 가격: ₩22,000\n",
      "   • 주요 식재료: 이탈리아산 아르보리오 쌀, 블랙 트러플, 파르미지아노 레지아노 치즈\n",
      "   • 설명: 크리미한 텍스처의 리조또에 고급 블랙 트러플을 듬뿍 얹어 풍부한 향과 맛을 즐길 수 있는 메뉴입니다. 24개월 숙성된 파르미지아노 레지아노 치즈를 사용하여 깊은 맛을 더했으며, 주문 즉시 조리하여 최상의 상태로 제공됩니다.\n",
      "\n",
      "3. 연어 타르타르\n",
      "   • 가격: ₩18,000\n",
      "   • 주요 식재료: 노르웨이산 생연어, 아보카도, 케이퍼, 적양파\n",
      "   • 설명: 신선한 노르웨이산 생연어를 곱게 다져 아보카도, 케이퍼, 적양파와 함께 섞어 만든 타르타르입니다. 레몬 드레싱으로 상큼한 맛을 더했으며, 바삭한 브리오쉬 토스트와 함께 제공됩니다. 전채요리로 완벽한 메뉴입니다.\n",
      "\n",
      "4. 버섯 크림 수프\n",
      "   • 가격: ₩10,000\n",
      "   • 주요 식재료: 양송이버섯, 표고버섯, 생크림, 트러플 오일\n",
      "   • 설명: 양송이버섯과 표고버섯을 오랜 시간 정성스레 끓여 만든 크림 수프입니다. 부드러운 텍스처와 깊은 버섯 향이 특징이며, 최상급 트러플 오일을 살짝 뿌려 고급스러운 향을 더했습니다. 파슬리를 곱게 다져 고명으로 올려 제공됩니다.\n",
      "\n",
      "5. 가든 샐러드\n",
      "   • 가격: ₩12,000\n",
      "   • 주요 식재료: 유기농 믹스 그린, 체리 토마토, 오이, 당근, 발사믹 드레싱\n",
      "   • 설명: 신선한 유기농 채소들로 구성된 건강한 샐러드입니다. 아삭한 식감의 믹스 그린에 달콤한 체리 토마토, 오이, 당근을 더해 다양한 맛과 식감을 즐길 \n",
      "첫 번째 문서 메타데이터: {'source': './data/restaurant_menu.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 단일 텍스트 파일 로드\n",
    "text_loader = TextLoader(\"./data/restaurant_menu.txt\", encoding=\"utf-8\")\n",
    "text_docs = text_loader.load()\n",
    "\n",
    "print(f\"문서 수: {len(text_docs)}\")\n",
    "print(f\"첫 번째 문서 내용:\\n{text_docs[0].page_content[:1000]}\")  # 첫 1000자 출력\n",
    "print(f\"첫 번째 문서 메타데이터: {text_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4519ae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문서 수: 2\n",
      "첫 번째 문서 내용:\n",
      "1. 시그니처 스테이크\n",
      "   • 가격: ₩35,000\n",
      "   • 주요 식재료: 최상급 한우 등심, 로즈메리 감자, 그릴드 아스파라거스\n",
      "   • 설명: 셰프의 특제 시그니처 메뉴로, 21일간 건조 숙성한 최상급 한우 등심을 사용합니다. 미디엄 레어로 조리하여 육즙을 최대한 보존하며, 로즈메리 향의 감자와 아삭한 그릴드 아스파라거스가 곁들여집니다. 레드와인 소스와 함께 제공되어 풍부한 맛을 더합니다.\n",
      "\n",
      "2. 트러플 리조또\n",
      "   • 가격: ₩22,000\n",
      "   • 주요 식재료: 이탈리아산 아르보리오 쌀, 블랙 트러플, 파르미지아노 레지아노 치즈\n",
      "   • 설명: 크리미한 텍스처의 리조또에 고급 블랙 트러플을 듬뿍 얹어 풍부한 향과 맛을 즐길 수 있는 메뉴입니다. 24개월 숙성된 파르미지아노 레지아노 치즈를 사용하여 깊은 맛을 더했으며, 주문 즉시 조리하여 최상의 상태로 제공됩니다.\n",
      "\n",
      "3. 연어 타르타르\n",
      "   • 가격: ₩18,000\n",
      "   • 주요 식재료: 노르웨이산 생연어, 아보카도, 케이퍼, 적양파\n",
      "   • 설명: 신선한 노르웨이산 생연어를 곱게 다져 아보카도, 케이퍼, 적양파와 함께 섞어 만든 타르타르입니다. 레몬 드레싱으로 상큼한 맛을 더했으며, 바삭한 브리오쉬 토스트와 함께 제공됩니다. 전채요리로 완벽한 메뉴입니다.\n",
      "\n",
      "4. 버섯 크림 수프\n",
      "   • 가격: ₩10,000\n",
      "   • 주요 식재료: 양송이버섯, 표고버섯, 생크림, 트러플 오일\n",
      "   • 설명: 양송이버섯과 표고버섯을 오랜 시간 정성스레 끓여 만든 크림 수프입니다. 부드러운 텍스처와 깊은 버섯 향이 특징이며, 최상급 트러플 오일을 살짝 뿌려 고급스러운 향을 더했습니다. 파슬리를 곱게 다져 고명으로 올려 제공됩니다.\n",
      "\n",
      "5. 가든 샐러드\n",
      "   • 가격: ₩12,000\n",
      "   • 주요 식재료: 유기농 믹스 그린, 체리 토마토, 오이, 당근, 발사믹 드레싱\n",
      "   • 설명: 신선한 유기농 채소들로 구성된 건강한 샐러드입니다. 아삭한 식감의 믹스 그린에 달콤한 체리 토마토, 오이, 당근을 더해 다양한 맛과 식감을 즐길 \n",
      "첫 번째 문서 메타데이터: {'source': 'data\\\\restaurant_menu.txt'}\n"
     ]
    }
   ],
   "source": [
    "# 디렉토리 내 모든 텍스트 파일 로드\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "directory_loader = DirectoryLoader(\n",
    "    \"./data/\",\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"}\n",
    ")\n",
    "all_text_docs = directory_loader.load()\n",
    "\n",
    "print(f\"전체 문서 수: {len(all_text_docs)}\")\n",
    "print(f\"첫 번째 문서 내용:\\n{all_text_docs[0].page_content[:1000]}\")  # 첫 1000자 출력\n",
    "print(f\"첫 번째 문서 메타데이터: {all_text_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5cb485",
   "metadata": {},
   "source": [
    "### 🎯 실습 1: 웹 문서 로더 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45ce4946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페이지 1: 9859 문자\n",
      "메타데이터: {'source': 'https://python.langchain.com/docs/tutorials/', 'title': 'Tutorials | 🦜️🔗 LangChain', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'language': 'en'}\n",
      "페이지 2: 16323 문자\n",
      "메타데이터: {'source': 'https://python.langchain.com/docs/concepts/', 'title': 'Conceptual guide | 🦜️🔗 LangChain', 'description': 'This guide provides explanations of the key concepts behind the LangChain framework and AI applications more broadly.', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "# 다음 웹 페이지들을 로드하고 메타데이터를 출력해보세요\n",
    "urls = [\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "    \"https://python.langchain.com/docs/concepts/\"\n",
    "]\n",
    "\n",
    "\n",
    "# 여기에 코드를 작성하세요\n",
    "\n",
    "# 기본 웹 문서 로드\n",
    "web_loader = WebBaseLoader(\n",
    "    web_paths=urls\n",
    ")\n",
    "\n",
    "# 문서 로드\n",
    "web_docs = web_loader.load()\n",
    "\n",
    "\n",
    "for i, doc in enumerate(web_docs[:2]):\n",
    "    print(f\"페이지 {i+1}: {len(doc.page_content)} 문자\")\n",
    "    print(f\"메타데이터: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb33946",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 텍스트 분할 (Text Splitting)\n",
    "\n",
    "### 🎯 텍스트 분할이 필요한 이유\n",
    "1. **토큰 제한**: LLM은 입력 토큰 수에 제한이 있음\n",
    "2. **검색 정확도**: 작은 청크가 더 정확한 검색 결과 제공\n",
    "3. **메모리 효율성**: 대용량 문서의 효율적 처리\n",
    "\n",
    "### 📊 분할 전략 비교\n",
    "| 방법 | 장점 | 단점 | 사용 사례 |\n",
    "|------|------|------|----------|\n",
    "| CharacterTextSplitter | 단순, 빠름 | 문맥 고려 안함 | 간단한 텍스트 |\n",
    "| RecursiveCharacterTextSplitter | 문맥 보존 우수 | 계산 복잡 | 일반적인 문서 |\n",
    "| SemanticChunker | 의미 기반 분할 | 느림, 비용 많음 | 중요한 문서 |\n",
    "| TokenTextSplitter | 정확한 토큰 수 | 토크나이저 의존 | API 비용 최적화 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8089d804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 문서 개수: 1\n"
     ]
    }
   ],
   "source": [
    "# PDF 로더 초기화\n",
    "pdf_loader = PyPDFLoader('./data/labor_law.pdf', mode='single')  # 'single' 또는 'page' 모드 선택 가능\n",
    "\n",
    "# 동기 로딩\n",
    "pdf_docs = pdf_loader.load()\n",
    "print(f'PDF 문서 개수: {len(pdf_docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa31164",
   "metadata": {},
   "source": [
    "### 1. CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2cb664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 문서의 텍스트 길이: 39539\n"
     ]
    }
   ],
   "source": [
    "long_text = pdf_docs[0].page_content\n",
    "print(f'첫 번째 문서의 텍스트 길이: {len(long_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a007e618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크 수: 1\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 기본 설정\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",        # 구분자\n",
    "    chunk_size=1000,         # 청크 크기\n",
    "    chunk_overlap=200,       # 중복 크기\n",
    "    length_function=len,     # 길이 측정 함수\n",
    "    is_separator_regex=False # 정규식 여부\n",
    ")\n",
    "\n",
    "# 텍스트 분할\n",
    "chunks = text_splitter.split_text(long_text)\n",
    "print(f\"분할된 청크 수: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7c7fe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크 수: 50\n",
      "청크 1 길이: 936 문자\n",
      "청크 2 길이: 944 문자\n",
      "청크 3 길이: 971 문자\n",
      "청크 4 길이: 930 문자\n",
      "청크 5 길이: 973 문자\n",
      "청크 6 길이: 961 문자\n",
      "청크 7 길이: 995 문자\n",
      "청크 8 길이: 971 문자\n",
      "청크 9 길이: 996 문자\n",
      "청크 10 길이: 972 문자\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 기본 설정\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",        # 구분자\n",
    "    chunk_size=1000,         # 청크 크기\n",
    "    chunk_overlap=200,       # 중복 크기\n",
    "    length_function=len,     # 길이 측정 함수\n",
    "    is_separator_regex=False # 정규식 여부\n",
    ")\n",
    "\n",
    "# 텍스트 분할\n",
    "chunks = text_splitter.split_text(long_text)\n",
    "print(f\"분할된 청크 수: {len(chunks)}\")\n",
    "\n",
    "for i, chunk in enumerate(chunks[:10]):\n",
    "    print(f\"청크 {i+1} 길이: {len(chunk)} 문자\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f3dedbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 620, which is longer than the specified 500\n",
      "Created a chunk of size 555, which is longer than the specified 500\n",
      "Created a chunk of size 539, which is longer than the specified 500\n",
      "Created a chunk of size 548, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 단위로 분할된 청크 수: 103\n",
      "청크 1 길이: 620 문자\n",
      "청크 2 길이: 470 문자\n",
      "청크 3 길이: 465 문자\n",
      "청크 4 길이: 410 문자\n",
      "청크 5 길이: 492 문자\n",
      "청크 6 길이: 490 문자\n",
      "청크 7 길이: 423 문자\n",
      "청크 8 길이: 395 문자\n",
      "청크 9 길이: 350 문자\n",
      "청크 10 길이: 285 문자\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "# 법률 문서와 공문서에 적합한 문장 분할 정규식 패턴\n",
    "# 문장 끝 후 공백이 있고, 특정 패턴이 따라오지 않는 경우만 분할 (목록 번호나 조항 번호 앞, 괄호로 된 항목 표시 앞, 기타 구두점 앞)\n",
    "sentence_pattern = r'(?<=[.!?])\\s+(?!\\s*(?:\\d+|호|조|항|]|\\)|[가-힣]{1,2}\\s*\\)|[A-Za-z]\\s*\\)|[,;:]))'\n",
    "\n",
    "# 정규식을 사용한 문장 단위 분할기 생성\n",
    "sentence_splitter = CharacterTextSplitter(\n",
    "    separator=sentence_pattern,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    is_separator_regex=True,\n",
    "    keep_separator=True\n",
    ")\n",
    "\n",
    "# 문장 단위로 분할\n",
    "sentence_chunks = sentence_splitter.split_text(long_text)\n",
    "print(f\"문장 단위로 분할된 청크 수: {len(sentence_chunks)}\")\n",
    "for i, chunk in enumerate(sentence_chunks[:10]):\n",
    "    print(f\"청크 {i+1} 길이: {len(chunk)} 문자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ac488bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 문서 청크 내용: 법제처                                                            1                                                       국가법령정보센터\n",
      "근로기준법\n",
      " \n",
      "근로기준법\n",
      "[시행 2021. 11. 19.] [법률 제18176호, 2021. 5. 18., 일부개정]\n",
      "고용노동부 (근로기준정책과 - 해고, 취업규칙, 기타) 044-202-7534\n",
      "고용노동부 (근로기준정책과 - 소년) 044-202-7535\n",
      "고용노동부 (근로기준정책과 - 임금) 044-202-7548\n",
      "고용노동부 (여성고용정책과 - 여성) 044-202-7475\n",
      "고용노동부 (임금근로시간정책과 - 근로시간, 휴게) 044-202-7545\n",
      "고용노동부 (임금근로시간정책과 - 휴일, 연차휴가) 044-202-7973\n",
      "고용노동부 (임금근로시간정책과 - 제63조 적용제외, 특례업종) 044-202-7530\n",
      "고용노동부 (임금근로시간정책과 - 유연근로시간제) 044-202-7549\n",
      "       제1장 총칙\n",
      " \n",
      "제1조(목적) 이 법은 헌법에 따라 근로조건의 기준을 정함으로써 근로자의 기본적 생활을 보장, 향상시키며 균형 있는\n",
      "국민경제의 발전을 꾀하는 것을 목적으로 한다.\n"
     ]
    }
   ],
   "source": [
    "print(f\"첫 번째 문서 청크 내용: {sentence_chunks[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a04b70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 번째 문서 청크 내용: 제2조(정의) ① 이 법에서 사용하는 용어의 뜻은 다음과 같다. <개정 2018. 3. 20., 2019. 1. 15., 2020. 5. 26.>\n",
      "1. “근로자”란 직업의 종류와 관계없이 임금을 목적으로 사업이나 사업장에 근로를 제공하는 사람을 말한다.\n",
      "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
      "말한다.\n",
      "3. “근로”란 정신노동과 육체노동을 말한다.\n",
      "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
      "결된 계약을 말한다.\n",
      "5. “임금”이란 사용자가 근로의 대가로 근로자에게 임금, 봉급, 그 밖에 어떠한 명칭으로든지 지급하는 모든 금품을\n",
      "말한다.\n",
      "6. “평균임금”이란 이를 산정하여야 할 사유가 발생한 날 이전 3개월 동안에 그 근로자에게 지급된 임금의 총액을\n",
      "그 기간의 총일수로 나눈 금액을 말한다.\n"
     ]
    }
   ],
   "source": [
    "print(f\"두 번째 문서 청크 내용: {sentence_chunks[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2f1195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세 번째 문서 청크 내용: “평균임금”이란 이를 산정하여야 할 사유가 발생한 날 이전 3개월 동안에 그 근로자에게 지급된 임금의 총액을\n",
      "그 기간의 총일수로 나눈 금액을 말한다. 근로자가 취업한 후 3개월 미만인 경우도 이에 준한다.\n",
      "7. “1주”란 휴일을 포함한 7일을 말한다.\n",
      "8. “소정(所定)근로시간”이란 제50조, 제69조 본문 또는 「산업안전보건법」 제139조제1항에 따른 근로시간의 범위에\n",
      "서 근로자와 사용자 사이에 정한 근로시간을 말한다.\n",
      "9. “단시간근로자”란 1주 동안의 소정근로시간이 그 사업장에서 같은 종류의 업무에 종사하는 통상 근로자의 1주\n",
      "동안의 소정근로시간에 비하여 짧은 근로자를 말한다.\n",
      "② 제1항제6호에 따라 산출된 금액이 그 근로자의 통상임금보다 적으면 그 통상임금액을 평균임금으로 한다.\n",
      " \n",
      "제3조(근로조건의 기준) 이 법에서 정하는 근로조건은 최저기준이므로 근로 관계 당사자는 이 기준을 이유로 근로조건\n",
      "을 낮출 수 없다.\n"
     ]
    }
   ],
   "source": [
    "print(f\"세 번째 문서 청크 내용: {sentence_chunks[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1824d6d1",
   "metadata": {},
   "source": [
    "### 2. RecursiveCharacterTextSplitter\n",
    "\n",
    "- 재귀적으로 텍스트를 분할하여 문맥을 최대한 보존하는 분할 도구\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93c8a641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 수: 50\n",
      "청크 1: 936 문자\n",
      "청크 2: 944 문자\n",
      "청크 3: 971 문자\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 기본 재귀 분할기\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", sentence_pattern]  # 우선순위 순서 (큰 구분자부터 작은 구분자 순서로 재귀적 분할)\n",
    "    # separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # 우선순위 순서 (큰 구분자부터 작은 구분자 순서로 재귀적 분할)\n",
    ")\n",
    "\n",
    "# Document 객체 분할\n",
    "chunks = text_splitter.split_documents(pdf_docs)\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "\n",
    "# 각 청크의 길이 확인\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"청크 {i+1}: {len(chunk.page_content)} 문자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfe18e1",
   "metadata": {},
   "source": [
    "### 3. 토큰 기반 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de34cd7a",
   "metadata": {},
   "source": [
    "#### 🔧 TikToken 토크나이저 기반 분할\n",
    "- OpenAI 임베딩 모델이 사용하는 토크나이저를 사용하여 정확한 토큰 수로 텍스트를 분할하는 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c97df91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1: 492 토큰, 620 문자\n",
      "청크 2: 449 토큰, 476 문자\n",
      "청크 3: 475 토큰, 473 문자\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 토크나이저 사용\n",
    "token_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",  # GPT-4 인코딩\n",
    "    chunk_size=500,              # 토큰 수 기준\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = token_splitter.split_documents([pdf_docs[0]])\n",
    "\n",
    "# 토큰 수 확인\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    token_count = len(tokenizer.encode(chunk.page_content))\n",
    "    print(f\"청크 {i+1}: {token_count} 토큰, {len(chunk.page_content)} 문자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ba7a0",
   "metadata": {},
   "source": [
    "#### 🤗 Hugging Face 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e50854e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ys\\ktds-llm\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1: 284 토큰, 620 문자\n",
      "청크 2: 298 토큰, 594 문자\n",
      "청크 3: 273 토큰, 464 문자\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# BGE-M3 토크나이저 사용\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "\n",
    "hf_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = hf_splitter.split_documents([pdf_docs[0]])\n",
    "\n",
    "# 토큰 수 확인\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    token_count = len(tokenizer(chunk.page_content)[\"input_ids\"])\n",
    "    print(f\"청크 {i+1}: {token_count} 토큰, {len(chunk.page_content)} 문자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0bbc2e",
   "metadata": {},
   "source": [
    "### 4. **Semantic Chunking**\n",
    "\n",
    "- **SemanticChunker**는 텍스트를 의미 단위로 **분할**하는 특수한 텍스트 분할도구 \n",
    "\n",
    "- 단순 길이 기반이 아닌 **의미 기반**으로 텍스트를 청크화하는데 효과적\n",
    "\n",
    "- **breakpoint_threshold_type**: Text Splitting의 다양한 임계값(Threshold) 설정 방식 (통계적 기법) \n",
    "\n",
    "    - **Gradient** 방식: 임베딩 벡터 간의 **기울기 변화**를 기준으로 텍스트를 분할\n",
    "    - **Percentile** 방식: 임베딩 거리의 **백분위수**를 기준으로 분할 지점을 결정 (기본값: 95%)\n",
    "    - **Standard Deviation** 방식: 임베딩 거리의 **표준편차**를 활용하여 유의미한 변화점을 찾아서 분할\n",
    "    - **Interquartile** 방식: 임베딩 거리의 **사분위수 범위**를 기준으로 이상치를 감지하여 분할\n",
    "\n",
    "- 설치: pip install langchain_experimental 또는 uv add langchain_experimental\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b01cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker \n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 임베딩 모델을 사용하여 SemanticChunker를 초기화 \n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"),         # OpenAI 임베딩 사용\n",
    "    breakpoint_threshold_type=\"gradient\",  # 임계값 타입 설정 (gradient, percentile, standard_deviation, interquartile)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "956587ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 수: 40\n",
      "각 청크의 길이: [151, 542, 3166, 5231, 129, 50, 911, 2377, 313, 137, 1999, 2, 275, 2412, 9, 1209, 111, 5859, 2120, 351, 223, 514, 2, 179, 1996, 2, 515, 2, 391, 2, 97, 1845, 2512, 1151, 175, 2, 1565, 82, 426, 295]\n"
     ]
    }
   ],
   "source": [
    "chunks = text_splitter.split_documents(pdf_docs)\n",
    "\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"각 청크의 길이: {list(len(chunk.page_content) for chunk in chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568bc61e",
   "metadata": {},
   "source": [
    "### 🎯 실습 2: 텍스트 분할 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a4c826a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################################################################\n",
      "문자 단위 분할기 분할된 청크 수: 2\n",
      "문자 단위 분할기 청크 1 길이: 963 문자\n",
      "문자 단위 분할기 청크 2 길이: 324 문자\n",
      "##########################################################################\n",
      "재귀 분할기 생성된 청크 수: 2\n",
      "재귀 분할기 청크 1: 906 문자\n",
      "재귀 분할기 청크 2: 193 문자\n",
      "##########################################################################\n",
      "OpenAI 토크나이저 청크 1: 284 토큰, 301 문자\n",
      "OpenAI 토크나이저 청크 2: 463 토큰, 484 문자\n",
      "OpenAI 토크나이저 청크 3: 437 토큰, 407 문자\n",
      "##########################################################################\n",
      "BGE-M3 토크나이저 청크 1: 155 토큰, 301 문자\n",
      "BGE-M3 토크나이저 청크 2: 245 토큰, 484 문자\n",
      "BGE-M3 토크나이저 청크 3: 248 토큰, 407 문자\n",
      "##########################################################################\n",
      "SemanticChunker 생성된 청크 수: 3\n",
      "SemanticChunker 각 청크의 길이: [64, 209, 816]\n"
     ]
    }
   ],
   "source": [
    "# 다음 텍스트를 다양한 방법으로 분할하고 결과를 비교해보세요\n",
    "sample_text = \"\"\"\n",
    "제1번 우리나라는 대한민국입니다.한화이글스는 대전을 연고로 하는 구단으로, 1999년 한국시리즈 우승을 차지했다. '절친 야구'로 유명한 정근우, 이용규 등의 선수들이 팀을 대표했다. 최근 몇 년간 성적이 부진했지만,  젊은 선수들의 육성에 힘쓰며 재건을 꾀하고 있다.\n",
    "\n",
    "\n",
    "\n",
    "제2번 인공지능은 현대 기술의 핵심입니다. \n",
    "머신러닝을 통해 컴퓨터는 학습할 수 있습니다.\n",
    "\n",
    "\n",
    "제3번 딥러닝은 신경망을 기반으로 합니다.\n",
    "자연어 처리는 텍스트를 이해하는 기술입니다.\n",
    "\n",
    "\n",
    "제4번 컴퓨터 비전은 이미지를 분석합니다.\n",
    "강화학습은 행동을 통해 학습합니다.\n",
    "\n",
    "1. “근로자”란 직업의 종류와 관계없이 임금을 목적으로 사업이나 사업장에 근로를 제공하는 사람을 말한다.\n",
    "2. “사용자”란 사업주 또는 사업 경영 담당자, 그 밖에 근로자에 관한 사항에 대하여 사업주를 위하여 행위하는 자를\n",
    "말한다.\n",
    "3. “근로”란 정신노동과 육체노동을 말한다.\n",
    "4. “근로계약”이란 근로자가 사용자에게 근로를 제공하고 사용자는 이에 대하여 임금을 지급하는 것을 목적으로 체\n",
    "결된 계약을 말한다.\n",
    "5. “임금”이란 사용자가 근로의 대가로 근로자에게 임금, 봉급, 그 밖에 어떠한 명칭으로든지 지급하는 모든 금품을\n",
    "말한다.\n",
    "6. “평균임금”이란 이를 산정하여야 할 사유가 발생한 날 이전 3개월 동안에 그 근로자에게 지급된 임금의 총액을\n",
    "그 기간의 총일수로 나눈 금액을 말한다.\n",
    "\n",
    "\n",
    "2. 트러플 리조또\n",
    "   • 가격: ₩22,000\n",
    "   • 주요 식재료: 이탈리아산 아르보리오 쌀, 블랙 트러플, 파르미지아노 레지아노 치즈\n",
    "   • 설명: 크리미한 텍스처의 리조또에 고급 블랙 트러플을 듬뿍 얹어 풍부한 향과 맛을 즐길 수 있는 메뉴입니다. 24개월 숙성된 파르미지아노 레지아노 치즈를 사용하여 깊은 맛을 더했으며, 주문 즉시 조리하여 최상의 상태로 제공됩니다.\n",
    "\n",
    "3. 연어 타르타르\n",
    "   • 가격: ₩18,000\n",
    "   • 주요 식재료: 노르웨이산 생연어, 아보카도, 케이퍼, 적양파\n",
    "   • 설명: 신선한 노르웨이산 생연어를 곱게 다져 아보카도, 케이퍼, 적양파와 함께 섞어 만든 타르타르입니다. 레몬 드레싱으로 상큼한 맛을 더했으며, 바삭한 브리오쉬 토스트와 함께 제공됩니다. 전채요리로 완벽한 메뉴입니다.\n",
    "\n",
    "   \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 여기에 코드를 작성하세요\n",
    "print(\"##########################################################################\")\n",
    "\n",
    "# 1. 문자 단위 분할기\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",        # 구분자\n",
    "    chunk_size=1000,         # 청크 크기\n",
    "    chunk_overlap=200,       # 중복 크기\n",
    "    length_function=len,     # 길이 측정 함수\n",
    "    is_separator_regex=False # 정규식 여부\n",
    ")\n",
    "\n",
    "# 텍스트 분할\n",
    "chunks = text_splitter.split_text(sample_text)\n",
    "print(f\"문자 단위 분할기 분할된 청크 수: {len(chunks)}\")\n",
    "\n",
    "for i, chunk in enumerate(chunks[:10]):\n",
    "    print(f\"문자 단위 분할기 청크 {i+1} 길이: {len(chunk)} 문자\")    \n",
    "\n",
    "print(\"##########################################################################\")\n",
    "\n",
    "# 2. 재귀 분할기\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", sentence_pattern]  # 우선순위 순서 (큰 구분자부터 작은 구분자 순서로 재귀적 분할)\n",
    "    # separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # 우선순위 순서 (큰 구분자부터 작은 구분자 순서로 재귀적 분할)\n",
    ")\n",
    "\n",
    "# Document 객체 분할\n",
    "chunks = text_splitter.split_text(sample_text)\n",
    "print(f\"재귀 분할기 생성된 청크 수: {len(chunks)}\")\n",
    "\n",
    "# 각 청크의 길이 확인\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"재귀 분할기 청크 {i+1}: {len(chunk)} 문자\")\n",
    "    \n",
    "print(\"##########################################################################\")\n",
    "\n",
    "\n",
    "# 3. OpenAI 토크나이저 사용\n",
    "token_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",  # GPT-4 인코딩\n",
    "    chunk_size=500,              # 토큰 수 기준\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = token_splitter.split_text(sample_text)\n",
    "\n",
    "# 토큰 수 확인\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    token_count = len(tokenizer.encode(chunk))\n",
    "    print(f\"OpenAI 토크나이저 청크 {i+1}: {token_count} 토큰, {len(chunk)} 문자\")\n",
    "\n",
    "\n",
    "print(\"##########################################################################\")\n",
    "\n",
    "\n",
    "# BGE-M3 토크나이저 사용\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "\n",
    "hf_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "chunks = hf_splitter.split_text(sample_text)\n",
    "\n",
    "# 토큰 수 확인\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    token_count = len(tokenizer(chunk)[\"input_ids\"])\n",
    "    print(f\"BGE-M3 토크나이저 청크 {i+1}: {token_count} 토큰, {len(chunk)} 문자\")\n",
    "\n",
    "\n",
    "print(\"##########################################################################\")\n",
    "\n",
    "\n",
    "# 임베딩 모델을 사용하여 SemanticChunker를 초기화 \n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"),         # OpenAI 임베딩 사용\n",
    "    breakpoint_threshold_type=\"gradient\",  # 임계값 타입 설정 (gradient, percentile, standard_deviation, interquartile)\n",
    ")\n",
    "chunks = text_splitter.split_text(sample_text)\n",
    "\n",
    "print(f\"SemanticChunker 생성된 청크 수: {len(chunks)}\")\n",
    "print(f\"SemanticChunker 각 청크의 길이: {list(len(chunk) for chunk in chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec29fae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 문서 임베딩 (Document Embedding)\n",
    "\n",
    "### 🎯 임베딩이란?\n",
    "텍스트를 고차원 벡터 공간의 숫자 배열로 변환하여 의미적 유사도를 계산할 수 있게 하는 기술입니다.\n",
    "\n",
    "### 📊 임베딩 모델 비교\n",
    "| 모델 | 차원 | 언어 지원 | 비용 | 성능 | 사용 사례 |\n",
    "|------|------|----------|------|------|----------|\n",
    "| OpenAI text-embedding-3-small | 1536 | 다국어 | 유료 | 높음 | 프로덕션 |\n",
    "| OpenAI text-embedding-3-large | 3072 | 다국어 | 유료 | 최고 | 고성능 요구 |\n",
    "| BAAI/bge-m3 | 1024 | 다국어 | 무료 | 높음 | 한국어 특화 |\n",
    "| sentence-transformers/all-MiniLM-L6-v2 | 384 | 영어 | 무료 | 중간 | 로컬 개발 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d3272",
   "metadata": {},
   "source": [
    "### 1. OpenAI 임베딩\n",
    "\n",
    "#### 🔧 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faf5008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 차원: 1536\n",
      "컨텍스트 길이: 8191\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 기본 임베딩 모델\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=1536,           # 차원 수 (기본값)\n",
    "    show_progress_bar=True,    # 진행률 표시\n",
    "    max_retries=3             # 재시도 횟수\n",
    ")\n",
    "\n",
    "print(f\"임베딩 차원: {embeddings_model.dimensions}\")\n",
    "print(f\"컨텍스트 길이: {embeddings_model.embedding_ctx_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9801824",
   "metadata": {},
   "source": [
    "#### 📝 문서 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19286db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터 수: 5\n",
      "각 벡터 차원: 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 문서 컬렉션 임베딩\n",
    "documents = [\n",
    "    \"인공지능은 컴퓨터 과학의 한 분야입니다.\",\n",
    "    \"머신러닝은 인공지능의 하위 분야입니다.\",\n",
    "    \"딥러닝은 머신러닝의 한 종류입니다.\",\n",
    "    \"자연어 처리는 컴퓨터가 인간의 언어를 이해하는 기술입니다.\",\n",
    "    \"컴퓨터 비전은 이미지를 분석하는 기술입니다.\"\n",
    "]\n",
    "\n",
    "# 배치 임베딩 (효율적)\n",
    "doc_embeddings = embeddings_model.embed_documents(documents)\n",
    "print(f\"임베딩 벡터 수: {len(doc_embeddings)}\")\n",
    "print(f\"각 벡터 차원: {len(doc_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfa6525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리 임베딩 차원: 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 쿼리 임베딩\n",
    "query = \"AI 기술에 대해 알려주세요\"\n",
    "query_embedding = embeddings_model.embed_query(query)\n",
    "print(f\"쿼리 임베딩 차원: {len(query_embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67317e58",
   "metadata": {},
   "source": [
    "#### 💡 차원 축소 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ab31808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "축소된 임베딩 벡터 수: 5\n",
      "축소된 각 벡터 차원: 512\n"
     ]
    }
   ],
   "source": [
    "# 비용 절약을 위한 차원 축소\n",
    "compact_embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\", \n",
    "    dimensions=512  # 원래 1536에서 512로 축소\n",
    ")\n",
    "\n",
    "# 성능과 비용의 균형점 찾는 것이 중요!!!\n",
    "compact_doc_embeddings = compact_embeddings.embed_documents(documents)\n",
    "print(f\"축소된 임베딩 벡터 수: {len(compact_doc_embeddings)}\")\n",
    "print(f\"축소된 각 벡터 차원: {len(compact_doc_embeddings[0])}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137bbef1",
   "metadata": {},
   "source": [
    "### 2. Hugging Face 임베딩\n",
    "\n",
    "#### 🤗 BGE-M3 모델 (한국어 우수)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83222ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 임베딩 차원: 1024\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# BGE-M3 모델 (다국어, 한국어 성능 우수)\n",
    "embeddings_bge = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs={'device': 'cpu'},        # 'cuda' for GPU\n",
    "    encode_kwargs={'normalize_embeddings': True}  # L2 정규화 - 벡터의 각 차원을 벡터의 L2 노름(크기)으로 나누어 단위 벡터로 변환 (벡터 크기 1로 정규화)\n",
    ")\n",
    "\n",
    "# BGE-M3 모델로 문서 임베딩\n",
    "bge_hf_embeddings = embeddings_bge.embed_documents(documents)\n",
    "print(f\"한국어 임베딩 차원: {len(bge_hf_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a79ffb",
   "metadata": {},
   "source": [
    "#### 📱 경량 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2ab84bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경량 모델 한국어 임베딩 차원: 768\n"
     ]
    }
   ],
   "source": [
    "# 빠른 처리를 위한 경량 모델\n",
    "embedding_gte = HuggingFaceEmbeddings(\n",
    "    model_name=\"Alibaba-NLP/gte-multilingual-base\",\n",
    "    model_kwargs={'device': 'cpu', 'trust_remote_code': True},  # trust_remote_code 필요 \n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "    \n",
    "# 경량 모델로 문서 임베딩\n",
    "alibaba_hf_embeddings = embedding_gte.embed_documents(documents)\n",
    "print(f\"경량 모델 한국어 임베딩 차원: {len(alibaba_hf_embeddings[0])}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc083cd",
   "metadata": {},
   "source": [
    "### 3. Ollama 임베딩 (로컬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ad5bbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로컬 임베딩 벡터 수: 5\n",
      "각 벡터 차원: 1024\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# Ollama 서버가 실행 중이어야 함\n",
    "embeddings_ollama = OllamaEmbeddings(\n",
    "    model=\"bge-m3\",                    # 사용할 모델\n",
    "    # base_url=\"http://localhost:11434\"  # Ollama 서버 주소\n",
    ")\n",
    "\n",
    "# 로컬 임베딩\n",
    "local_embeddings = embeddings_ollama.embed_documents(documents)\n",
    "\n",
    "print(f\"로컬 임베딩 벡터 수: {len(local_embeddings)}\")\n",
    "print(f\"각 벡터 차원: {len(local_embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441df2cb",
   "metadata": {},
   "source": [
    "### 4. 유사도 계산 및 검색\n",
    "\n",
    "#### 📏 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e87b9bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 딥러닝에 대해 알려주세요\n",
      "가장 유사한 문서: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "유사도 점수: 0.5867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utils.math import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def find_most_similar(query, doc_embeddings, documents, embeddings_model):\n",
    "    \"\"\"가장 유사한 문서 찾기\"\"\"\n",
    "    # 쿼리 임베딩\n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "    \n",
    "    # 코사인 유사도 계산\n",
    "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "    \n",
    "    # 가장 유사한 문서 인덱스\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "    \n",
    "    return {\n",
    "        \"document\": documents[most_similar_idx],\n",
    "        \"similarity\": similarities[most_similar_idx],\n",
    "        \"index\": most_similar_idx\n",
    "    }\n",
    "\n",
    "# 쿼리와 문서 임베딩을 사용하여 가장 유사한 문서 찾기 (OpenAI)\n",
    "query = \"딥러닝에 대해 알려주세요\"\n",
    "result = find_most_similar(query, doc_embeddings, documents, embeddings_model)\n",
    "\n",
    "print(f\"쿼리: {query}\")\n",
    "print(f\"가장 유사한 문서: {result['document']}\")\n",
    "print(f\"유사도 점수: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45d78393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 딥러닝에 대해 알려주세요\n",
      "가장 유사한 문서: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "유사도 점수: 0.7360\n"
     ]
    }
   ],
   "source": [
    "# HuggingFaceEmbeddings를 사용한 유사도 검색 (BGE-M3)\n",
    "result = find_most_similar(query, bge_hf_embeddings, documents, embeddings_bge)\n",
    "print(f\"쿼리: {query}\")\n",
    "print(f\"가장 유사한 문서: {result['document']}\")\n",
    "print(f\"유사도 점수: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34a9fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 딥러닝에 대해 알려주세요\n",
      "가장 유사한 문서: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "유사도 점수: 0.7886\n"
     ]
    }
   ],
   "source": [
    "# Alibaba-NLP/gte-multilingual-base 모델로 유사도 검색\n",
    "result = find_most_similar(query, alibaba_hf_embeddings, documents, embedding_gte)\n",
    "print(f\"쿼리: {query}\")\n",
    "print(f\"가장 유사한 문서: {result['document']}\")\n",
    "print(f\"유사도 점수: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "157eced6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 딥러닝에 대해 알려주세요\n",
      "가장 유사한 문서: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "유사도 점수: 0.7350\n"
     ]
    }
   ],
   "source": [
    "# Ollama 모델로 유사도 검색 (bge-m3)\n",
    "result = find_most_similar(query, local_embeddings, documents, embeddings_ollama)\n",
    "print(f\"쿼리: {query}\")\n",
    "print(f\"가장 유사한 문서: {result['document']}\")\n",
    "print(f\"유사도 점수: {result['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547d40c4",
   "metadata": {},
   "source": [
    "### 🎯 실습 3: 임베딩 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2eec6277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: 기계학습이란 무엇인가요?\n",
      "embeddings_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 기계학습이란 무엇인가요?\n",
      "가장 유사한 문서: 인공지능은 컴퓨터 과학의 한 분야입니다.\n",
      "유사도 점수: 0.2103\n",
      "###########################################################################\n",
      "embeddings_bge\n",
      "쿼리: 기계학습이란 무엇인가요?\n",
      "가장 유사한 문서: 머신러닝은 인공지능의 하위 분야입니다.\n",
      "유사도 점수: 0.5844\n",
      "###########################################################################\n",
      "embedding_gte\n",
      "쿼리: 기계학습이란 무엇인가요?\n",
      "가장 유사한 문서: 딥러닝은 머신러닝의 한 종류입니다.\n",
      "유사도 점수: 0.6941\n",
      "###########################################################################\n",
      "embeddings_ollama\n",
      "쿼리: 기계학습이란 무엇인가요?\n",
      "가장 유사한 문서: 머신러닝은 인공지능의 하위 분야입니다.\n",
      "유사도 점수: 0.5835\n",
      "###########################################################################\n",
      "query: 이미지 인식 기술에 대해 설명해주세요\n",
      "embeddings_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 이미지 인식 기술에 대해 설명해주세요\n",
      "가장 유사한 문서: 컴퓨터 비전은 이미지를 분석하는 기술입니다.\n",
      "유사도 점수: 0.4341\n",
      "###########################################################################\n",
      "embeddings_bge\n",
      "쿼리: 이미지 인식 기술에 대해 설명해주세요\n",
      "가장 유사한 문서: 컴퓨터 비전은 이미지를 분석하는 기술입니다.\n",
      "유사도 점수: 0.6503\n",
      "###########################################################################\n",
      "embedding_gte\n",
      "쿼리: 이미지 인식 기술에 대해 설명해주세요\n",
      "가장 유사한 문서: 컴퓨터 비전은 이미지를 분석하는 기술입니다.\n",
      "유사도 점수: 0.6549\n",
      "###########################################################################\n",
      "embeddings_ollama\n",
      "쿼리: 이미지 인식 기술에 대해 설명해주세요\n",
      "가장 유사한 문서: 컴퓨터 비전은 이미지를 분석하는 기술입니다.\n",
      "유사도 점수: 0.6493\n",
      "###########################################################################\n",
      "query: 언어 모델의 작동 원리는?\n",
      "embeddings_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 언어 모델의 작동 원리는?\n",
      "가장 유사한 문서: 자연어 처리는 컴퓨터가 인간의 언어를 이해하는 기술입니다.\n",
      "유사도 점수: 0.3740\n",
      "###########################################################################\n",
      "embeddings_bge\n",
      "쿼리: 언어 모델의 작동 원리는?\n",
      "가장 유사한 문서: 자연어 처리는 컴퓨터가 인간의 언어를 이해하는 기술입니다.\n",
      "유사도 점수: 0.5323\n",
      "###########################################################################\n",
      "embedding_gte\n",
      "쿼리: 언어 모델의 작동 원리는?\n",
      "가장 유사한 문서: 자연어 처리는 컴퓨터가 인간의 언어를 이해하는 기술입니다.\n",
      "유사도 점수: 0.5514\n",
      "###########################################################################\n",
      "embeddings_ollama\n",
      "쿼리: 언어 모델의 작동 원리는?\n",
      "가장 유사한 문서: 자연어 처리는 컴퓨터가 인간의 언어를 이해하는 기술입니다.\n",
      "유사도 점수: 0.5311\n",
      "###########################################################################\n"
     ]
    }
   ],
   "source": [
    "# 다음 질문들에 대해 다른 임베딩 모델들의 검색 성능을 비교해보세요\n",
    "queries = [\n",
    "    \"기계학습이란 무엇인가요?\",\n",
    "    \"이미지 인식 기술에 대해 설명해주세요\",\n",
    "    \"언어 모델의 작동 원리는?\"\n",
    "]\n",
    "\n",
    "# 여기에 코드를 작성하세요\n",
    "\n",
    "\n",
    "def find_most_similar(query, doc_embeddings, documents, embeddings_model):\n",
    "    \"\"\"가장 유사한 문서 찾기\"\"\"\n",
    "    # 쿼리 임베딩\n",
    "    query_embedding = embeddings_model.embed_query(query)\n",
    "    \n",
    "    # 코사인 유사도 계산\n",
    "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "    \n",
    "    # 가장 유사한 문서 인덱스\n",
    "    most_similar_idx = np.argmax(similarities)\n",
    "    \n",
    "    return {\n",
    "        \"document\": documents[most_similar_idx],\n",
    "        \"similarity\": similarities[most_similar_idx],\n",
    "        \"index\": most_similar_idx\n",
    "    }\n",
    "\n",
    "# 쿼리와 문서 임베딩을 사용하여 가장 유사한 문서 찾기 (OpenAI)\n",
    "\n",
    "for query in queries:\n",
    "    print(\"query:\", query)\n",
    "    print(\"embeddings_model\")\n",
    "    result = find_most_similar(query, doc_embeddings, documents, embeddings_model)\n",
    "    print(f\"쿼리: {query}\")\n",
    "    print(f\"가장 유사한 문서: {result['document']}\")\n",
    "    print(f\"유사도 점수: {result['similarity']:.4f}\")\n",
    "    print(\"###########################################################################\")\n",
    "\n",
    "\n",
    "    # HuggingFaceEmbeddings를 사용한 유사도 검색 (BGE-M3)\n",
    "    print(\"embeddings_bge\")\n",
    "    result = find_most_similar(query, bge_hf_embeddings, documents, embeddings_bge)\n",
    "    print(f\"쿼리: {query}\")\n",
    "    print(f\"가장 유사한 문서: {result['document']}\")\n",
    "    print(f\"유사도 점수: {result['similarity']:.4f}\")\n",
    "    print(\"###########################################################################\")\n",
    "\n",
    "\n",
    "    # Alibaba-NLP/gte-multilingual-base 모델로 유사도 검색\n",
    "    print(\"embedding_gte\")\n",
    "    result = find_most_similar(query, alibaba_hf_embeddings, documents, embedding_gte)\n",
    "    print(f\"쿼리: {query}\")\n",
    "    print(f\"가장 유사한 문서: {result['document']}\")\n",
    "    print(f\"유사도 점수: {result['similarity']:.4f}\")\n",
    "    print(\"###########################################################################\")\n",
    "\n",
    "\n",
    "    # Ollama 모델로 유사도 검색 (bge-m3)\n",
    "    print(\"embeddings_ollama\")\n",
    "    result = find_most_similar(query, local_embeddings, documents, embeddings_ollama)\n",
    "    print(f\"쿼리: {query}\")\n",
    "    print(f\"가장 유사한 문서: {result['document']}\")\n",
    "    print(f\"유사도 점수: {result['similarity']:.4f}\")\n",
    "    print(\"###########################################################################\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4ffa75",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 벡터 저장소 (Vector Store)\n",
    "\n",
    "### 🎯 벡터 저장소란?\n",
    "임베딩된 벡터를 효율적으로 저장하고 유사도 기반 검색을 수행하는 특수 데이터베이스\n",
    "\n",
    "### 📊 벡터 저장소 비교\n",
    "| 종류 | 장점 | 단점 | 사용 사례 |\n",
    "|------|------|------|----------|\n",
    "| Chroma | 설치 간단, 로컬 친화적 | 대용량 처리 한계 | 개발, 프로토타입 |\n",
    "| FAISS | 매우 빠름, 확장성 우수 | 설정 복잡 | 대용량 검색 |\n",
    "| Pinecone | 완전 관리형, 고성능 | 유료, 클라우드 의존 | 프로덕션 |\n",
    "| Weaviate | GraphQL 지원, 하이브리드 검색 | 학습 곡선 | 복합 검색 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2bd40b",
   "metadata": {},
   "source": [
    "### 🚀 Chroma 설치 및 설정\n",
    "```bash\n",
    "pip install langchain-chroma\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb5d82",
   "metadata": {},
   "source": [
    "#### 📚 기본 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61cc15d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 수: 89\n",
      "저장된 문서 수: 89\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 문서 준비\n",
    "pdf_loader = PyPDFLoader('./data/labor_law.pdf', mode='single')\n",
    "pdf_docs = pdf_loader.load()\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "chunks = text_splitter.split_documents(pdf_docs)\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "\n",
    "# 임베딩 모델\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Chroma 벡터 저장소 생성\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"labor_law\",\n",
    "    persist_directory=\"./local_chroma_db\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}  # 유사도 메트릭\n",
    ")\n",
    "\n",
    "print(f\"저장된 문서 수: {chroma_db._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d65858",
   "metadata": {},
   "source": [
    "#### 💾 벡터 저장소 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26d62249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 문서 수: 89\n"
     ]
    }
   ],
   "source": [
    "# 기존 벡터 저장소 로드\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"labor_law\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./local_chroma_db\"\n",
    ")\n",
    "\n",
    "print(f\"로드된 문서 수: {chroma_db._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581bc215",
   "metadata": {},
   "source": [
    "#### 🔍 기본 검색 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1887e37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 결과 수: 5\n",
      "결과 1: ② 1일의 근로시간은 휴게시간을 제외하고 8시간을 초과할 수 없다.\n",
      "③ 제1항 및 제2항에 따라 근로시간을 산정하는 경우 작업을 위하여 근로자가 사용자의 지휘ㆍ감독 아래에 있는 대...\n",
      "----------------------------------------\n",
      "결과 2: 근로기준법\n",
      "[제목개정 2021. 1. 5.]\n",
      " \n",
      "제51조의2(3개월을 초과하는 탄력적 근로시간제) ① 사용자는 근로자대표와의 서면 합의에 따라 다음 각 호의 사항을\n",
      "정하면 3개월을...\n",
      "----------------------------------------\n",
      "결과 3: 다. 다만, 조사와 관련된 내용을 사용자에게 보고하거나 관계 기관의 요청에 따라 필요한 정보를 제공하는 경우는\n",
      "제외한다.<신설 2021. 4. 13.>\n",
      "[본조신설 2019. 1. ...\n",
      "----------------------------------------\n",
      "결과 4: 자의 근로시간을 기준으로 산정한 비율에 따라 결정되어야 한다.\n",
      "② 제1항에 따라 근로조건을 결정할 때에 기준이 되는 사항이나 그 밖에 필요한 사항은 대통령령으로 정한다.\n",
      "③ 4주 ...\n",
      "----------------------------------------\n",
      "결과 5: 간의 근로시간이 제50조제1항의 근로시간을 초과하지 아니하는 범위에서 특정한 주에 제50조제1항의 근로시간을,\n",
      "특정한 날에 제50조제2항의 근로시간을 초과하여 근로하게 할 수 있다...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. 유사도 검색\n",
    "query = \"탄력 근로에 대해 설명해주세요\"\n",
    "similar_docs = chroma_db.similarity_search(\n",
    "    query=query,\n",
    "    k=5,  # 상위 5개 결과\n",
    "    filter={\"source\": \"./data/labor_law.pdf\"}  # 메타데이터 필터\n",
    ")\n",
    "\n",
    "print(f\"검색 결과 수: {len(similar_docs)}\")\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"결과 {i+1}: {doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3be3abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수: 0.6894\n",
      "내용: ② 1일의 근로시간은 휴게시간을 제외하고 8시간을 초과할 수 없다.\n",
      "③ 제1항 및 제2항에 따라 근로시간을 산정하는 경우 작업을 위하여 근로자가 사용자의 지휘ㆍ감독 아래에 있는 대...\n",
      "--------------------------------------------------\n",
      "점수: 0.7102\n",
      "내용: 근로기준법\n",
      "[제목개정 2021. 1. 5.]\n",
      " \n",
      "제51조의2(3개월을 초과하는 탄력적 근로시간제) ① 사용자는 근로자대표와의 서면 합의에 따라 다음 각 호의 사항을\n",
      "정하면 3개월을...\n",
      "--------------------------------------------------\n",
      "점수: 0.7346\n",
      "내용: 다. 다만, 조사와 관련된 내용을 사용자에게 보고하거나 관계 기관의 요청에 따라 필요한 정보를 제공하는 경우는\n",
      "제외한다.<신설 2021. 4. 13.>\n",
      "[본조신설 2019. 1. ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 2. 점수와 함께 검색 (유사도 점수 포함)\n",
    "docs_with_scores = chroma_db.similarity_search_with_score(query, k=3)\n",
    "\n",
    "for doc, score in docs_with_scores:\n",
    "    print(f\"점수: {score:.4f}\")\n",
    "    print(f\"내용: {doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e9d91",
   "metadata": {},
   "source": [
    "#### 🎛️ 메타데이터 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2dca4ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필터링된 검색 결과 수: 0\n"
     ]
    }
   ],
   "source": [
    "# 복합 필터 조건\n",
    "filter_criteria = {\n",
    "    \"$and\": [\n",
    "        {\"source\": {\"$eq\": \"./data/labor_law.pdf\"}},\n",
    "        {\"page\": {\"$gte\": 10}}  # 10페이지 이상\n",
    "    ]\n",
    "}\n",
    "\n",
    "filtered_results = chroma_db.similarity_search(\n",
    "    query=query,\n",
    "    k=5,\n",
    "    filter=filter_criteria, \n",
    ")\n",
    "\n",
    "print(f\"필터링된 검색 결과 수: {len(filtered_results)}\")\n",
    "for i, doc in enumerate(filtered_results):\n",
    "    print(f\"결과 {i+1}: {doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366f2ff",
   "metadata": {},
   "source": [
    "#### 🔄 문서 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3e9dab7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_doc_1']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새 문서 추가\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "new_docs = [Document(page_content=\"새로운 내용\", metadata={\"source\": \"new\"})]\n",
    "chroma_db.add_documents(new_docs, ids=[\"new_doc_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b4ab92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 삭제 (ID 기반)\n",
    "chroma_db.delete(ids=[\"new_doc_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 컬렉션 삭제\n",
    "# chroma_db.delete_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e64df58",
   "metadata": {},
   "source": [
    "### 🎯 실습 4: 벡터 저장소 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4729b6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로드된 문서 수: 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 문서 삭제 (ID 기반)\n",
    "# chroma_db.delete(ids=[\"web_docs1\"])\n",
    "# chroma_db.delete_collection()\n",
    "\n",
    "# 기존 벡터 저장소 로드 확인\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"web_docs1\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./web_chroma_db\"\n",
    ")\n",
    "print(f\"로드된 문서 수: {chroma_db._collection.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b42f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "웹 문서 개수: 1\n",
      "생성된 청크 수: 12\n",
      "저장된 문서 수: 12\n",
      "로드된 문서 수: 12\n",
      "점수: 1.0141\n",
      "내용: Tutorials | 🦜️🔗 LangChain...\n",
      "--------------------------------------------------\n",
      "점수: 1.1930\n",
      "내용: prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsH...\n",
      "--------------------------------------------------\n",
      "점수: 1.2091\n",
      "내용: Skip to main contentOur new LangChain Academy Course Deep Research with LangGraph is now live! Enrol...\n",
      "--------------------------------------------------\n",
      "점수: 1.2130\n",
      "내용: to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesH...\n",
      "--------------------------------------------------\n",
      "점수: 1.2134\n",
      "내용: LangSmith​\n",
      "LangSmith allows you to closely trace, monitor and evaluate your LLM application.\n",
      "It seam...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 다음 단계로 나만의 벡터 저장소를 구축해보세요:\n",
    "# 1. 웹에서 문서 로드\n",
    "# 2. 적절한 크기로 분할\n",
    "# 3. 임베딩 및 저장\n",
    "# 4. 검색 테스트\n",
    "\n",
    "# 여기에 코드를 작성하세요\n",
    "\n",
    "\n",
    "# 1. 웹 문서 로드\n",
    "urls = [\n",
    "    \"https://python.langchain.com/docs/tutorials/\",\n",
    "]\n",
    "web_loader = WebBaseLoader(web_paths=urls)\n",
    "web_docs = web_loader.load()\n",
    "print(f'웹 문서 개수: {len(web_docs)}')\n",
    "\n",
    "\n",
    "# 2. 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "chunks = text_splitter.split_documents(web_docs)\n",
    "print(f\"생성된 청크 수: {len(chunks)}\")\n",
    "\n",
    "\n",
    "\n",
    "# 3. 임베딩 모델 \n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "# 벡터에 저장할때, chunk를 embedding 해서 저장하는 과정이 같이 진행됨.\n",
    "# bge_hf_embeddings = embeddings_bge.embed_documents(chunks)\n",
    "\n",
    "\n",
    "# Chroma 벡터 저장소 생성\n",
    "chroma_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"web_docs1\",\n",
    "    persist_directory=\"./web_chroma_db\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}  # 유사도 메트릭\n",
    ")\n",
    "print(f\"저장된 문서 수: {chroma_db._collection.count()}\")\n",
    "\n",
    "\n",
    "# 기존 벡터 저장소 로드 확인\n",
    "chroma_db = Chroma(\n",
    "    collection_name=\"web_docs1\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./web_chroma_db\"\n",
    ")\n",
    "print(f\"로드된 문서 수: {chroma_db._collection.count()}\")\n",
    "\n",
    "\n",
    "# 4. 검색 테스트\n",
    "query = \"LangChain 튜토리얼에 대해 알려주세요\"\n",
    "# similar_docs = chroma_db.similarity_search(\n",
    "#     query=query,\n",
    "#     k=5  # 상위 5개 결과\n",
    "# )\n",
    "# print(f\"검색 결과 수: {len(similar_docs)}\")\n",
    "# for i, doc in enumerate(similar_docs):\n",
    "#     print(f\"결과 {i+1}: {doc.page_content[:100]}...\")\n",
    "#     print(\"-\" * 40)\n",
    "\n",
    "\n",
    "docs_with_scores = chroma_db.similarity_search_with_score(query, k=5)\n",
    "\n",
    "for doc, score in docs_with_scores:\n",
    "    print(f\"점수: {score:.4f}\")\n",
    "    print(f\"내용: {doc.page_content[:100]}...\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# # HuggingFaceEmbeddings를 사용한 유사도 검색 (BGE-M3)\n",
    "# result = find_most_similar(query, bge_hf_embeddings, documents, embeddings_bge)\n",
    "# print(f\"쿼리: {query}\")\n",
    "# print(f\"가장 유사한 문서: {result['document']}\")\n",
    "# print(f\"유사도 점수: {result['similarity']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9528dd45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 검색기 (Retriever)\n",
    "\n",
    "### 🎯 Retriever란?\n",
    "벡터 저장소를 기반으로 사용자 질의에 가장 관련성 높은 문서를 검색하는 인터페이스입니다.\n",
    "\n",
    "### 📊 검색 전략 비교\n",
    "| 전략 | 설명 | 장점 | 단점 | 사용 사례 |\n",
    "|------|------|------|------|----------|\n",
    "| similarity | 단순 유사도 검색 | 빠름, 직관적 | 다양성 부족 | 일반적인 검색 |\n",
    "| similarity_score_threshold | 임계값 기반 검색 | 품질 보장 | 결과 수 불안정 | 고품질 결과 필요 |\n",
    "| mmr | 최대 한계 관련성 | 다양성 우수 | 느림 | 포괄적 정보 필요 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e572d",
   "metadata": {},
   "source": [
    "### 1. 기본 유사도 검색\n",
    "\n",
    "#### 🔍 Top-K 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6f3c1f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서 수: 5\n",
      "문서 1:\n",
      "내용: Tutorials | 🦜️🔗 LangChain...\n",
      "출처: https://python.langchain.com/docs/tutorials/\n",
      "--------------------------------------------------\n",
      "문서 2:\n",
      "내용: LangSmith​\n",
      "LangSmith allows you to closely trace, monitor and evaluate your LLM application.\n",
      "It seamlessly integrates with LangChain, and you can use it to inspect and debug individual steps of your c...\n",
      "출처: https://python.langchain.com/docs/tutorials/\n",
      "--------------------------------------------------\n",
      "문서 3:\n",
      "내용: from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDoc...\n",
      "출처: https://python.langchain.com/docs/tutorials/\n",
      "--------------------------------------------------\n",
      "문서 4:\n",
      "내용: to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question ...\n",
      "출처: https://python.langchain.com/docs/tutorials/\n",
      "--------------------------------------------------\n",
      "문서 5:\n",
      "내용: toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load w...\n",
      "출처: https://python.langchain.com/docs/tutorials/\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 벡터 저장소를 Retriever로 변환\n",
    "retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}  # 상위 5개 결과\n",
    ")\n",
    "\n",
    "# 검색 실행\n",
    "query = \"탄력 근로에 대해 설명해주세요\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"검색된 문서 수: {len(retrieved_docs)}\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"문서 {i+1}:\")\n",
    "    print(f\"내용: {doc.page_content[:200]}...\")\n",
    "    print(f\"출처: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d1339",
   "metadata": {},
   "source": [
    "### 2. 임계값 기반 검색\n",
    "\n",
    "#### 📏 점수 임계값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c6ed0f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ys\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1083: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='9d2e73e2-be6e-484e-a6a0-af8b392c3b12', metadata={'language': 'en', 'title': 'Tutorials | 🦜️🔗 LangChain', 'source': 'https://python.langchain.com/docs/tutorials/', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.'}, page_content='Tutorials | 🦜️🔗 LangChain'), -0.14500621518745982), (Document(id='e64f05a3-877c-4e74-9f4e-e16fc14f5081', metadata={'language': 'en', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'source': 'https://python.langchain.com/docs/tutorials/', 'title': 'Tutorials | 🦜️🔗 LangChain'}, page_content='LangSmith\\u200b\\nLangSmith allows you to closely trace, monitor and evaluate your LLM application.\\nIt seamlessly integrates with LangChain, and you can use it to inspect and debug individual steps of your chains as you build.\\nLangSmith documentation is hosted on a separate site.\\nYou can peruse LangSmith tutorials here.\\nEvaluation\\u200b\\nLangSmith helps you evaluate the performance of your LLM applications. The tutorial below is a great way to get started:\\n\\nEvaluate your LLM application\\nEdit this pagePreviousIntroductionNextBuild a Question Answering application over a Graph DatabaseGet startedOrchestrationLangSmithEvaluationCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.'), -0.18556185157967353), (Document(id='ce0c69f1-fbf5-45f5-8fcd-fc9f70398a96', metadata={'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'language': 'en', 'source': 'https://python.langchain.com/docs/tutorials/', 'title': 'Tutorials | 🦜️🔗 LangChain'}, page_content='from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsOn this pageTutorials'), -0.19232996110094702), (Document(id='5d040946-8a78-421f-9aef-4d98a21d5189', metadata={'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'language': 'en', 'source': 'https://python.langchain.com/docs/tutorials/', 'title': 'Tutorials | 🦜️🔗 LangChain'}, page_content='to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with LangChainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured'), -0.19979374650374115), (Document(id='b88a517e-62f0-4b07-a660-5a1ea3070e2c', metadata={'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'language': 'en', 'title': 'Tutorials | 🦜️🔗 LangChain', 'source': 'https://python.langchain.com/docs/tutorials/'}, page_content='toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse'), -0.20201496971396238), (Document(id='6d052fad-5a6f-487e-a11e-52749a5049a8', metadata={'title': 'Tutorials | 🦜️🔗 LangChain', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'language': 'en', 'source': 'https://python.langchain.com/docs/tutorials/'}, page_content='prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with LangChainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or'), -0.22584597797378003), (Document(id='0d5a3436-e6cc-4349-b487-a2f84c5785cd', metadata={'title': 'Tutorials | 🦜️🔗 LangChain', 'language': 'en', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'source': 'https://python.langchain.com/docs/tutorials/'}, page_content=\"databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow to deal with high-cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch\"), -0.25436388437540325), (Document(id='26a86494-633e-4a8e-a9b8-0fddbd1c9c46', metadata={'title': 'Tutorials | 🦜️🔗 LangChain', 'source': 'https://python.langchain.com/docs/tutorials/', 'language': 'en', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.'}, page_content=\"one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow to deal with high-cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to\"), -0.2544389057657528), (Document(id='ac7b10a0-4af6-48f7-93ba-ecdc08590f7d', metadata={'language': 'en', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'title': 'Tutorials | 🦜️🔗 LangChain', 'source': 'https://python.langchain.com/docs/tutorials/'}, page_content='Skip to main contentOur new LangChain Academy Course Deep Research with LangGraph is now live! Enroll for free.IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between'), -0.261040450941711), (Document(id='c4b6f47c-14c5-4c01-8b14-a0dd5936a9c4', metadata={'title': 'Tutorials | 🦜️🔗 LangChain', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'source': 'https://python.langchain.com/docs/tutorials/', 'language': 'en'}, page_content=\"New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.\\nGet started\\u200b\\nFamiliarize yourself with LangChain's open-source components by building simple applications.\\nIf you're looking to get started with chat models, vector stores,\\nor other LangChain components from a specific provider, check out our supported integrations.\"), -0.2642906473114772)]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n",
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    }
   ],
   "source": [
    "# 유사도 점수 임계값 기반 검색\n",
    "threshold_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"score_threshold\": 0.3,  # 0.3 이상의 유사도만\n",
    "        \"k\": 10                  # 최대 10개까지\n",
    "    }\n",
    ")\n",
    "\n",
    "retrieved_docs = threshold_retriever.invoke(query)\n",
    "\n",
    "# 실제 유사도 점수 확인\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    # 실제 유사도 계산\n",
    "    doc_embedding = embeddings.embed_query(doc.page_content)\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "    similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "    \n",
    "    print(f\"문서 {i+1} (유사도: {similarity:.4f}):\")\n",
    "    print(f\"{doc.page_content[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f5a0c",
   "metadata": {},
   "source": [
    "### 3. MMR (Maximal Marginal Relevance) 검색\n",
    "\n",
    "#### 🎯 다양성을 고려한 검색\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5e66269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMR 검색 결과:\n",
      "문서 1: Tutorials | 🦜️🔗 LangChain...\n",
      "\n",
      "문서 2: LangSmith​\n",
      "LangSmith allows you to closely trace, monitor and evaluate your LLM application.\n",
      "It seamlessly integrates with LangChain, and you can use ...\n",
      "\n",
      "문서 3: from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigra...\n",
      "\n",
      "문서 4: one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow ...\n",
      "\n",
      "문서 5: New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.\n",
      "Get started​\n",
      "Fa...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MMR 검색 - 관련성과 다양성의 균형\n",
    "mmr_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,                # 최종 반환할 문서 수\n",
    "        \"fetch_k\": 20,         # 초기 후보 문서 수\n",
    "        \"lambda_mult\": 0.5     # 관련성 vs 다양성 (0=최대 다양성, 1=최대 관련성)\n",
    "    }\n",
    ")\n",
    "\n",
    "mmr_docs = mmr_retriever.invoke(query)\n",
    "\n",
    "print(\"MMR 검색 결과:\")\n",
    "for i, doc in enumerate(mmr_docs):\n",
    "    print(f\"문서 {i+1}: {doc.page_content[:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d898f7d",
   "metadata": {},
   "source": [
    "#### 🔧 lambda_mult 파라미터 실험\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c724ef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lambda 0.0 결과:\n",
      "----------------------------------------\n",
      "  1. Tutorials | 🦜️🔗 LangChain...\n",
      "  2. LangSmith​\n",
      "LangSmith allows you to closely trace, monitor and evaluate your LLM application.\n",
      "It seam...\n",
      "  3. one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing quer...\n",
      "========================================\n",
      "\n",
      "Lambda 0.25 결과:\n",
      "----------------------------------------\n",
      "  1. Tutorials | 🦜️🔗 LangChain...\n",
      "  2. LangSmith​\n",
      "LangSmith allows you to closely trace, monitor and evaluate your LLM application.\n",
      "It seam...\n",
      "  3. one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing quer...\n",
      "========================================\n",
      "\n",
      "Lambda 0.5 결과:\n",
      "----------------------------------------\n",
      "  1. Tutorials | 🦜️🔗 LangChain...\n",
      "  2. LangSmith​\n",
      "LangSmith allows you to closely trace, monitor and evaluate your LLM application.\n",
      "It seam...\n",
      "  3. one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing quer...\n",
      "========================================\n",
      "\n",
      "Lambda 0.75 결과:\n",
      "----------------------------------------\n",
      "  1. Tutorials | 🦜️🔗 LangChain...\n",
      "  2. LangSmith​\n",
      "LangSmith allows you to closely trace, monitor and evaluate your LLM application.\n",
      "It seam...\n",
      "  3. to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesH...\n",
      "========================================\n",
      "\n",
      "Lambda 1.0 결과:\n",
      "----------------------------------------\n",
      "  1. Tutorials | 🦜️🔗 LangChain...\n",
      "  2. LangSmith​\n",
      "LangSmith allows you to closely trace, monitor and evaluate your LLM application.\n",
      "It seam...\n",
      "  3. from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumen...\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# 다양한 lambda_mult 값으로 실험\n",
    "lambda_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "for lambda_val in lambda_values:\n",
    "    retriever = chroma_db.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\n",
    "            \"k\": 3,\n",
    "            \"fetch_k\": 10,\n",
    "            \"lambda_mult\": lambda_val\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    docs = retriever.invoke(query)\n",
    "    print(f\"\\nLambda {lambda_val} 결과:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"  {i+1}. {doc.page_content[:100]}...\")\n",
    "    \n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40825374",
   "metadata": {},
   "source": [
    "#### 🎛️ 메타데이터 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e4e00bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타데이터 기반 필터링 결과:\n"
     ]
    }
   ],
   "source": [
    "# 메타데이터 기반 필터링 retriever\n",
    "filtered_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "        \"filter\": {\n",
    "            \"source\": \"./data/labor_law.pdf\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "filtered_results = filtered_retriever.invoke(query)\n",
    "\n",
    "print(\"메타데이터 기반 필터링 결과:\")\n",
    "for i, doc in enumerate(filtered_results):\n",
    "    print(f\"문서 {i+1}: {doc.page_content[:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656541aa",
   "metadata": {},
   "source": [
    "#### 🔄 동적 검색 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "739cbb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "쿼리: 탄력근로\n",
      "길이: 1 단어\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ys\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1083: UserWarning: Relevance scores must be between 0 and 1, got [(Document(id='e64f05a3-877c-4e74-9f4e-e16fc14f5081', metadata={'language': 'en', 'title': 'Tutorials | 🦜️🔗 LangChain', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'source': 'https://python.langchain.com/docs/tutorials/'}, page_content='LangSmith\\u200b\\nLangSmith allows you to closely trace, monitor and evaluate your LLM application.\\nIt seamlessly integrates with LangChain, and you can use it to inspect and debug individual steps of your chains as you build.\\nLangSmith documentation is hosted on a separate site.\\nYou can peruse LangSmith tutorials here.\\nEvaluation\\u200b\\nLangSmith helps you evaluate the performance of your LLM applications. The tutorial below is a great way to get started:\\n\\nEvaluate your LLM application\\nEdit this pagePreviousIntroductionNextBuild a Question Answering application over a Graph DatabaseGet startedOrchestrationLangSmithEvaluationCommunityLangChain ForumTwitterSlackGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.'), -0.21453620835066967), (Document(id='5d040946-8a78-421f-9aef-4d98a21d5189', metadata={'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'language': 'en', 'source': 'https://python.langchain.com/docs/tutorials/', 'title': 'Tutorials | 🦜️🔗 LangChain'}, page_content='to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with LangChainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured'), -0.22124733533275642), (Document(id='9d2e73e2-be6e-484e-a6a0-af8b392c3b12', metadata={'language': 'en', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'source': 'https://python.langchain.com/docs/tutorials/', 'title': 'Tutorials | 🦜️🔗 LangChain'}, page_content='Tutorials | 🦜️🔗 LangChain'), -0.24402703260331848), (Document(id='6d052fad-5a6f-487e-a11e-52749a5049a8', metadata={'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'title': 'Tutorials | 🦜️🔗 LangChain', 'language': 'en', 'source': 'https://python.langchain.com/docs/tutorials/'}, page_content='prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with LangChainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or'), -0.2605670575392367), (Document(id='ce0c69f1-fbf5-45f5-8fcd-fc9f70398a96', metadata={'title': 'Tutorials | 🦜️🔗 LangChain', 'language': 'en', 'description': 'New to LangChain or LLM app development in general? Read this material to quickly get up and running building your first applications.', 'source': 'https://python.langchain.com/docs/tutorials/'}, page_content='from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsOn this pageTutorials'), -0.2644604148172791)]\n",
      "  self.vectorstore.similarity_search_with_relevance_scores(\n",
      "No relevant docs were retrieved using the relevance score threshold 0.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 결과: 0개 문서\n",
      "----------------------------------------\n",
      "\n",
      "쿼리: 탄력 근로에 대해 설명해주세요\n",
      "길이: 4 단어\n",
      "검색 결과: 5개 문서\n",
      "----------------------------------------\n",
      "\n",
      "쿼리: 탄력 근로 제도의 장점과 단점, 그리고 실제 적용 사례를 포함하여 자세히 설명해주세요\n",
      "길이: 12 단어\n",
      "검색 결과: 5개 문서\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class DynamicRetriever:\n",
    "    def __init__(self, vectorstore, embeddings):\n",
    "        self.vectorstore = vectorstore\n",
    "        self.embeddings = embeddings\n",
    "    \n",
    "    def retrieve(self, query, search_type=\"auto\", k=5):\n",
    "        \"\"\"쿼리 특성에 따라 동적으로 검색 전략 선택\"\"\"\n",
    "        \n",
    "        # 쿼리 복잡도 분석\n",
    "        query_length = len(query.split())\n",
    "        \n",
    "        if query_length <= 3:\n",
    "            # 짧은 쿼리: 높은 임계값\n",
    "            search_type = \"similarity_score_threshold\"\n",
    "            search_kwargs = {\"score_threshold\": 0.25, \"k\": k}\n",
    "        elif query_length > 10:\n",
    "            # 긴 쿼리: MMR로 다양성 확보\n",
    "            search_type = \"mmr\"\n",
    "            search_kwargs = {\"k\": k, \"fetch_k\": k*3, \"lambda_mult\": 0.3}\n",
    "        else:\n",
    "            # 중간 길이: 기본 유사도 검색\n",
    "            search_type = \"similarity\"\n",
    "            search_kwargs = {\"k\": k}\n",
    "        \n",
    "        retriever = self.vectorstore.as_retriever(\n",
    "            search_type=search_type,\n",
    "            search_kwargs=search_kwargs\n",
    "        )\n",
    "        \n",
    "        return retriever.invoke(query)\n",
    "\n",
    "# 사용 예시\n",
    "dynamic_retriever = DynamicRetriever(chroma_db, embeddings)\n",
    "\n",
    "queries = [\n",
    "    \"탄력근로\",  # 짧은 쿼리\n",
    "    \"탄력 근로에 대해 설명해주세요\",  # 중간 쿼리\n",
    "    \"탄력 근로 제도의 장점과 단점, 그리고 실제 적용 사례를 포함하여 자세히 설명해주세요\"  # 긴 쿼리\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n쿼리: {query}\")\n",
    "    print(f\"길이: {len(query.split())} 단어\")\n",
    "    docs = dynamic_retriever.retrieve(query)\n",
    "    print(f\"검색 결과: {len(docs)}개 문서\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e667b",
   "metadata": {},
   "source": [
    "### 🎯 실습 5: 검색 전략 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "14a0e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 질문에 대해 다른 검색 전략들의 결과를 비교해보세요\n",
    "test_query = \"근로시간 단축에 대한 규정은 무엇인가요?\"\n",
    "\n",
    "strategies = {\n",
    "    \"similarity\": {\"k\": 5},\n",
    "    \"similarity_score_threshold\": {\"score_threshold\": 0.3, \"k\": 10},\n",
    "    \"mmr\": {\"k\": 5, \"fetch_k\": 15, \"lambda_mult\": 0.5}\n",
    "}\n",
    "\n",
    "# 여기에 코드를 작성하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5231bd3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## RAG 체인 구현\n",
    "\n",
    "### 🎯 RAG 체인이란?\n",
    "검색(Retrieval)과 생성(Generation)을 연결하여 외부 지식을 기반으로 답변을 생성하는 파이프라인\n",
    "\n",
    "### 🔄 RAG 워크플로우\n",
    "`\n",
    "사용자 질문 → 관련 문서 검색 → 컨텍스트 구성 → LLM 프롬프트 → 답변 생성\n",
    "`\n",
    "\n",
    "### 1. 프롬프트 템플릿 설계\n",
    "\n",
    "#### 📝 기본 RAG 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "883b1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 기본 RAG 프롬프트 템플릿\n",
    "basic_template = \"\"\"주어진 컨텍스트를 기반으로 질문에 답변하세요.\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "basic_prompt = ChatPromptTemplate.from_template(basic_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8b3127",
   "metadata": {},
   "source": [
    "#### 🎨 고급 RAG 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "39c836c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_template = \"\"\"당신은 전문적인 문서 분석 AI입니다. 주어진 컨텍스트를 바탕으로 정확하고 유용한 답변을 제공하세요.\n",
    "\n",
    "## 답변 지침\n",
    "- 컨텍스트에 있는 정보만을 사용하여 답변하세요\n",
    "- 확실하지 않은 정보는 \"명확하지 않습니다\"라고 명시하세요\n",
    "- 답변은 논리적이고 구조화된 형태로 제공하세요\n",
    "- 가능한 경우 구체적인 예시나 수치를 포함하세요\n",
    "- 답변에 참조한 문서의 출처가 있다면 포함하세요 (문서명, 페이지, URL 등)\n",
    "\n",
    "## 컨텍스트\n",
    "{context}\n",
    "\n",
    "## 질문\n",
    "{question}\n",
    "\n",
    "## 답변 형식\n",
    "**핵심 답변:** (질문에 대한 직접적인 답변)\n",
    "\n",
    "**세부 설명:** (추가적인 설명이나 배경 정보)\n",
    "\n",
    "**관련 정보:** (컨텍스트에서 발견된 연관 정보)\n",
    "\n",
    "**답변:**\"\"\"\n",
    "\n",
    "advanced_prompt = ChatPromptTemplate.from_template(advanced_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cdf3ac",
   "metadata": {},
   "source": [
    "#### 🌟 도메인별 특화 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c05f366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_template = \"\"\"당신은 법률 문서 전문 AI입니다. 법률 조항을 정확히 해석하고 설명해주세요.\n",
    "\n",
    "## 법률 해석 원칙\n",
    "- 조문의 정확한 인용을 포함하세요\n",
    "- 법적 용어는 일반인이 이해할 수 있도록 설명하세요\n",
    "- 예외 조항이나 단서가 있다면 반드시 언급하세요\n",
    "- 관련 법령이나 시행령도 함께 언급하세요\n",
    "\n",
    "## 관련 법률 조항\n",
    "{context}\n",
    "\n",
    "## 법률 질의\n",
    "{question}\n",
    "\n",
    "## 법률 답변\n",
    "**해당 조항:** (관련 법률 조항 인용)\n",
    "\n",
    "**조항 해석:** (조항의 의미와 적용 범위)\n",
    "\n",
    "**주의사항:** (예외 조항이나 제한 사항)\n",
    "\n",
    "**답변:**\"\"\"\n",
    "\n",
    "legal_prompt = ChatPromptTemplate.from_template(legal_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf2074b",
   "metadata": {},
   "source": [
    "### 2. LLM 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "befd3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 설정\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.1,                   # 일관성 있는 답변\n",
    "    max_completion_tokens=1000,        # 답변 길이 제한\n",
    "    top_p=0.9,              # 다양성 제어\n",
    "    # frequency_penalty=0.1,  # 반복 방지\n",
    "    # presence_penalty=0.1    # 새로운 단어 장려\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54638f88",
   "metadata": {},
   "source": [
    "### 3. RAG 체인 구성\n",
    "\n",
    "#### 🔗 기본 LCEL 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c379da04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "탄력 근로제는 근로자가 일정 기간 동안 근로 시간을 자유롭게 조정할 수 있도록 하는 제도입니다. 예를 들어, 주당 법정 근로 시간 내에서 하루에 일하는 시간을 늘리거나 줄이는 대신, 다른 날에 근로 시간을 조정하여 전체 근로 시간을 맞추는 방식입니다. 이를 통해 근로자는 개인의 상황이나 업무량에 맞게 근무 시간을 유연하게 운영할 수 있고, 기업은 업무 효율성을 높일 수 있습니다. 다만, 탄력 근로제를 도입할 때는 근로기준법 등 관련 법규를 준수해야 하며, 근로자와의 합의가 필요합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"문서 리스트를 문자열로 포맷\"\"\"\n",
    "    return \"\\n\\n\".join([\n",
    "        f\"{doc.page_content}\" for doc in docs\n",
    "    ])\n",
    "\n",
    "# 기본 RAG 체인\n",
    "basic_rag_chain = (\n",
    "    RunnableParallel({\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    })\n",
    "    | basic_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 테스트\n",
    "query = \"탄력 근로에 대해 설명해주세요\"\n",
    "result = basic_rag_chain.invoke(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c118a3b",
   "metadata": {},
   "source": [
    "#### 🎯 고급 RAG 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2091aed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**핵심 답변:**  \n",
      "컨텍스트 내에는 탄력 근로에 대한 설명이나 정의가 포함되어 있지 않아, 탄력 근로에 대해 명확하게 설명할 수 없습니다.\n",
      "\n",
      "**세부 설명:**  \n",
      "탄력 근로제는 일반적으로 근로시간을 일정 기간 단위로 유연하게 조정하여 근로자와 사용자가 근로시간을 탄력적으로 운영할 수 있도록 하는 제도입니다. 하지만 주어진 컨텍스트에서는 이와 관련된 정보가 전혀 제공되지 않았습니다.\n",
      "\n",
      "**관련 정보:**  \n",
      "컨텍스트는 주로 LangChain과 LangSmith 관련 튜토리얼, 평가, 마이그레이션, 메모리 관리 등에 관한 내용으로 구성되어 있으며, 탄력 근로와 관련된 내용은 포함되어 있지 않습니다.\n",
      "\n",
      "**답변:**  \n",
      "주어진 컨텍스트에는 탄력 근로에 관한 정보가 포함되어 있지 않아, 이에 대해 설명드리기 어렵습니다. 추가적인 자료나 문서가 제공되면 그에 맞춰 답변을 드릴 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "def format_docs_with_metadata(docs):\n",
    "    \"\"\"메타데이터를 포함한 문서 포맷팅\"\"\"\n",
    "    formatted_docs = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        source = doc.metadata.get('source', 'Unknown')\n",
    "        page = doc.metadata.get('page', 'N/A')\n",
    "        \n",
    "        formatted_doc = f\"\"\"\n",
    "출처: {source}\n",
    "페이지: {page}\n",
    "내용: {doc.page_content}\n",
    "---\n",
    "\"\"\"\n",
    "        formatted_docs.append(formatted_doc)\n",
    "    \n",
    "    return \"\\n\".join(formatted_docs)\n",
    "\n",
    "\n",
    "# 고급 RAG 체인\n",
    "advanced_rag_chain = (\n",
    "    RunnableParallel({\n",
    "        \"context\": retriever | format_docs_with_metadata,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    })\n",
    "    | advanced_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 테스트\n",
    "query = \"탄력 근로에 대해 설명해주세요\"\n",
    "result = advanced_rag_chain.invoke(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc6522",
   "metadata": {},
   "source": [
    "### 🎯 실습 6: 완전한 RAG 시스템 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 요구사항을 만족하는 RAG 시스템을 구축해보세요:\n",
    "# 1. 여러 문서 형식 지원 (PDF, 웹, 텍스트)\n",
    "# 2. 동적 검색 전략 선택\n",
    "# 3. 도메인별 프롬프트 템플릿\n",
    "# 4. 응답 품질 평가\n",
    "\n",
    "class ComprehensiveRAGSystem:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_documents(self, sources):\n",
    "        \"\"\"다양한 소스에서 문서 로드\"\"\"\n",
    "        # 여기에 코드를 작성하세요\n",
    "        pass\n",
    "    \n",
    "    def setup_vector_store(self, documents):\n",
    "        \"\"\"벡터 저장소 구성\"\"\"\n",
    "        # 여기에 코드를 작성하세요\n",
    "        pass\n",
    "    \n",
    "    def query(self, question, domain=\"general\"):\n",
    "        \"\"\"도메인별 질의응답\"\"\"\n",
    "        # 여기에 코드를 작성하세요\n",
    "        pass\n",
    "\n",
    "# 여기에 구현 코드를 작성하세요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
