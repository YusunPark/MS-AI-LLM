{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  재순위화(Re-rank) 기법, 맥락 압축(Contextual Compression) 기법\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 개념 이해\n",
    "\n",
    "### 1.1 RAG 파이프라인의 한계점\n",
    "\n",
    "기본적인 RAG 시스템에서는 벡터 유사도만으로 문서를 검색하고 반환하는데, 이 과정에서 다음과 같은 문제점들이 발생합니다:\n",
    "\n",
    "#### 🚨 **주요 문제점들**\n",
    "\n",
    "1. **의미적 유사도의 한계**: 벡터 유사도가 항상 실제 관련성과 일치하지 않음\n",
    "2. **순위 정확도 문제**: 가장 관련성 높은 문서가 상위에 오지 않을 수 있음\n",
    "3. **노이즈 정보 포함**: 검색된 문서에 불필요한 정보가 많이 포함됨\n",
    "4. **컨텍스트 길이 제한**: LLM의 컨텍스트 윈도우 한계로 인한 정보 손실\n",
    "5. **비용 효율성**: 불필요한 토큰으로 인한 API 비용 증가\n",
    "\n",
    "### 1.2 해결책: 이중 단계 처리\n",
    "\n",
    "#### 🔄 **Two-Stage Retrieval Process**\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    A[Query] --> B[1차 검색<br/>벡터 유사도]\n",
    "    B --> C[대량의 후보 문서<br/>k=50~100개]\n",
    "    C --> D[2차 처리<br/>Re-ranking/Compression]\n",
    "    D --> E[정제된 결과<br/>k=3~10개]\n",
    "    E --> F[LLM]\n",
    "```\n",
    "\n",
    "### 1.3 재순위화 vs 맥락 압축\n",
    "\n",
    "| 특징 | 재순위화 (Re-ranking) | 맥락 압축 (Contextual Compression) |\n",
    "|------|----------------------|-----------------------------------|\n",
    "| **목적** | 검색 결과의 순서 최적화 | 관련 정보만 선별적 추출 |\n",
    "| **처리 방식** | 문서 전체 순위 재정렬 | 문서 내용 필터링/압축 |\n",
    "| **출력** | 순서가 바뀐 동일한 문서들 | 압축되거나 필터링된 문서들 |\n",
    "| **주요 장점** | 정확도 향상 | 비용 절감, 노이즈 제거 |\n",
    "| **사용 시점** | 검색 직후 | 검색 후 또는 재순위화 후 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 환경 설정\n",
    "\n",
    "### 2.1 필수 라이브러리 설치\n",
    "\n",
    "```bash\n",
    "# 기본 LangChain 및 RAG 구성 요소\n",
    "pip install langchain langchain-community langchain-openai\n",
    "pip install langchain-chroma\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 환경 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 경고 메시지 숨기기\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Langsmith tracing 여부를 확인 (true: langsmith 추적 활성화, false: langsmith 추적 비활성화)\n",
    "print(os.getenv('LANGSMITH_TRACING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 기본 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pprint import pprint\n",
    "\n",
    "# LangChain 핵심\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# 검색 및 압축\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import (\n",
    "    CrossEncoderReranker,\n",
    "    LLMListwiseRerank,\n",
    "    LLMChainFilter,\n",
    "    LLMChainExtractor,\n",
    "    EmbeddingsFilter,\n",
    "    DocumentCompressorPipeline\n",
    ")\n",
    "\n",
    "# 외부 모델\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "\n",
    "# 벡터 저장소\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 데이터 분석 및 시각화\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# # 한글 폰트 인식 - Windows\n",
    "import matplotlib \n",
    "font_name = matplotlib.font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "matplotlib.rc('font', family=font_name)\n",
    "\n",
    "# 한글 폰트 인식 - Mac\n",
    "# import matplotlib\n",
    "# matplotlib.rc('font', family='AppleGothic')\n",
    "\n",
    "# 마이너스 부호 인식\n",
    "matplotlib.rc(\"axes\", unicode_minus = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 벡터 저장소 및 기본 검색기 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 기존 벡터 저장소 로드: 39개 문서\n",
      "✅ 기본 검색기 생성 완료\n"
     ]
    }
   ],
   "source": [
    "def initialize_vector_store(embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\"), collection_name=\"hybrid_search_db\", persist_directory = \"./local_chroma_db\"):\n",
    "    \"\"\"\n",
    "    기존 벡터 저장소를 로드하거나 새로 생성\n",
    "    \n",
    "    Returns:\n",
    "        Chroma: 벡터 저장소 객체\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        # 기존 벡터 저장소 로드 시도     \n",
    "        vector_store = Chroma( \n",
    "            collection_name=collection_name, \n",
    "            embedding_function=embeddings,\n",
    "            persist_directory=persist_directory,\n",
    "        )   \n",
    "        \n",
    "        doc_count = vector_store._collection.count() # 저장소 내 문서 개수 확인\n",
    "        if doc_count > 0:\n",
    "            print(f\"✅ 기존 벡터 저장소 로드: {doc_count}개 문서\")\n",
    "            return vector_store\n",
    "        else:\n",
    "            print(\"⚠️ 빈 벡터 저장소입니다. 데이터를 추가해주세요.\")\n",
    "            return vector_store\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 벡터 저장소 로드 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "# 벡터 저장소 초기화\n",
    "vector_store = initialize_vector_store() \n",
    "\n",
    "if vector_store:\n",
    "    # 기본 검색기 생성\n",
    "    base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 5}) # 유사도 상위 5개 문서 검색\n",
    "    print(\"✅ 기본 검색기 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Document>\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다.\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "<Document>\n",
      "- **Model S:** 리프트백 차체 스타일과 듀얼 모터, 전륜 구동 레이아웃을 갖춘 풀사이즈 고급차. Model S 개발은 2007년 이전에 시작되었으며 배송은 2012년 6월에 시작되었습니다.\n",
      "- **Model X:** 듀얼 모터 또는 트리 모터, 전륜 구동 레이아웃을 갖춘 5인승, 6인승 및 7인승 구성으로 제공되는 중형 고급 크로스오버 SUV. 뒷좌석 승객 문은 관절형 \"팔콘 윙\" 디자인으로 수직으로 열립니다. Model X 프로토타입은 2012년 2월에 처음 공개되었으며 배송은 2015년 9월에 시작되었습니다.\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "<Document>\n",
      "- **Model Y:** 싱글 모터, 후륜 구동 또는 듀얼 모터, 전륜 구동 레이아웃을 갖춘 5인승 및 7인승 구성으로 제공되는 중형 크로스오버 SUV. 이 차량은 고급 Model X SUV보다 저렴하도록 설계되었습니다. Model Y 프로토타입은 2019년 3월에 처음 공개되었으며 배송은 2020년 3월에 시작되었습니다.\n",
      "- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다.\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "<Document>\n",
      "- **Model 3:** 패스트백 차체 스타일과 듀얼 모터, 전륜 구동 레이아웃 또는 후륜 모터, 후륜 구동 레이아웃을 갖춘 중형차. 이 차량은 고급 Model S 세단보다 저렴하도록 설계되었습니다. Model 3 프로토타입은 2016년에 처음 공개되었으며 일주일 만에 325,000건 이상의 유료 예약이 접수되었습니다.\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "<Document>\n",
      "| Tesla 모델 |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| 이름       | 제조년도 | 좌석  | 참고             |\n",
      "| Roadster   | 2008     | 2     | 2012년에 단종    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025년 출시 예정 |\n",
      "| Cybercab   |          | 2     | 2026년 출시 예정 |\n",
      "| Robovan    |          | 20    | 명시된 기간 없음 |\n",
      "\n",
      "### 사용 가능한 제품\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 기본 retriever 테스트 \n",
    "\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = base_retriever.invoke(query)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 재순위화(Re-ranking) 기법\n",
    "\n",
    "### 3.1 재순위화의 핵심 개념\n",
    "\n",
    "재순위화는 1차 검색으로 얻은 문서들을 더 정교한 기준으로 재평가하여 순서를 재정렬하는 기법입니다.\n",
    "\n",
    "#### 🎯 **재순위화의 작동 원리**\n",
    "\n",
    "1. **1차 검색**: 벡터 유사도로 많은 후보 문서 검색 (k=50~100)\n",
    "2. **정밀 분석**: 각 문서와 쿼리 간의 세밀한 관련성 평가\n",
    "3. **순위 재정렬**: 관련성 점수에 따라 문서 순서 재배치\n",
    "4. **상위 선택**: 가장 관련성 높은 상위 k개 문서 반환\n",
    "\n",
    "### 3.2 Cross-Encoder 재순위화\n",
    "\n",
    "Cross-Encoder는 쿼리와 문서를 함께 입력받아 직접적인 관련성 점수를 계산하는 모델입니다.\n",
    "\n",
    "- **Cross-Encoder** 모델을 활용하여 검색 결과의 정밀한 재정렬을 수행함\n",
    "- 검색 쿼리와 검색된 문서 간 유사도를 더 정확하게 계산함\n",
    "\n",
    "- 참고: https://www.sbert.net/examples/applications/cross-encoder/README.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cross_encoder_reranker(model_name=\"BAAI/bge-reranker-v2-m3\", top_n=5):\n",
    "    \"\"\"\n",
    "    Cross-Encoder 재순위화 시스템 생성\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): 사용할 Cross-Encoder 모델\n",
    "        top_n (int): 반환할 상위 문서 수\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: 재순위화 검색기\n",
    "    \"\"\"\n",
    "    print(f\"🔄 Cross-Encoder 재순위화 시스템 초기화\")\n",
    "    print(f\"   모델: {model_name}\")\n",
    "    print(f\"   상위 {top_n}개 문서 반환\")\n",
    "    \n",
    "    try:\n",
    "        # Cross-Encoder 모델 로드\n",
    "        cross_encoder_model = HuggingFaceCrossEncoder(model_name=model_name)\n",
    "        \n",
    "        # 재순위화 컴프레서 생성\n",
    "        reranker = CrossEncoderReranker(\n",
    "            model=cross_encoder_model, \n",
    "            top_n=top_n\n",
    "        )\n",
    "        \n",
    "        # 컨텍스트 압축 검색기 생성\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=reranker,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Cross-Encoder 재순위화 시스템 생성 완료\")\n",
    "        return compression_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Cross-Encoder 초기화 실패: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Cross-Encoder 재순위화 시스템 초기화\n",
      "   모델: BAAI/bge-reranker-v2-m3\n",
      "   상위 5개 문서 반환\n",
      "✅ Cross-Encoder 재순위화 시스템 생성 완료\n",
      "\n",
      "🔄 Cross-Encoder 재순위화 검색 결과:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "<Document>\n",
      "- **Model Y:** 싱글 모터, 후륜 구동 또는 듀얼 모터, 전륜 구동 레이아웃을 갖춘 5인승 및 7인승 구성으로 제공되는 중형 크로스오버 SUV. 이 차량은 고급 Model X SUV보다 저렴하도록 설계되었습니다. Model Y 프로토타입은 2019년 3월에 처음 공개되었으며 배송은 2020년 3월에 시작되었습니다.\n",
      "- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다.\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "<Document>\n",
      "| Tesla 모델 |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| 이름       | 제조년도 | 좌석  | 참고             |\n",
      "| Roadster   | 2008     | 2     | 2012년에 단종    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025년 출시 예정 |\n",
      "| Cybercab   |          | 2     | 2026년 출시 예정 |\n",
      "| Robovan    |          | 20    | 명시된 기간 없음 |\n",
      "\n",
      "### 사용 가능한 제품\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "<Document>\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다.\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "<Document>\n",
      "- **Model S:** 리프트백 차체 스타일과 듀얼 모터, 전륜 구동 레이아웃을 갖춘 풀사이즈 고급차. Model S 개발은 2007년 이전에 시작되었으며 배송은 2012년 6월에 시작되었습니다.\n",
      "- **Model X:** 듀얼 모터 또는 트리 모터, 전륜 구동 레이아웃을 갖춘 5인승, 6인승 및 7인승 구성으로 제공되는 중형 고급 크로스오버 SUV. 뒷좌석 승객 문은 관절형 \"팔콘 윙\" 디자인으로 수직으로 열립니다. Model X 프로토타입은 2012년 2월에 처음 공개되었으며 배송은 2015년 9월에 시작되었습니다.\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "<Document>\n",
      "- **Model 3:** 패스트백 차체 스타일과 듀얼 모터, 전륜 구동 레이아웃 또는 후륜 모터, 후륜 구동 레이아웃을 갖춘 중형차. 이 차량은 고급 Model S 세단보다 저렴하도록 설계되었습니다. Model 3 프로토타입은 2016년에 처음 공개되었으며 일주일 만에 325,000건 이상의 유료 예약이 접수되었습니다.\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 재순위화 시스템 생성\n",
    "cross_encoder_retriever = create_cross_encoder_reranker(top_n=5)\n",
    "\n",
    "# CrossEncoderReranker를 사용한 retriever를 사용하여 검색\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = cross_encoder_retriever.invoke(query) \n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"\\n🔄 Cross-Encoder 재순위화 검색 결과:\")\n",
    "print(\"-\"*200)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 평가 데이터셋 로드: 50개 질문\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rivian Automotive, Inc.의 설립 연도와 주요 사업 분야는 무엇입니까?</td>\n",
       "      <td>['Rivian Automotive, Inc.는 2009년에 설립된 미국의 전기 자...</td>\n",
       "      <td>Rivian Automotive, Inc.는 2009년에 설립된 미국의 전기 자동차...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168억 미국 달러는 리브니의 무슨 항목에 해당합니까?</td>\n",
       "      <td>['- **회사 유형:** 상장\\n- **거래소:** NASDAQ: RIVN\\n- ...</td>\n",
       "      <td>168억 미국 달러는 2023년 기준 리브니의 총 자산에 해당합니다.</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023년 기준 Rivian의 직원 수는 몇 명입니까?</td>\n",
       "      <td>['- **총 자본 (2023):** 91억 4천만 미국 달러\\n- **직원 수 (...</td>\n",
       "      <td>2023년 12월 기준 Rivian의 직원 수는 16,790명입니다.</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         user_input  \\\n",
       "0  Rivian Automotive, Inc.의 설립 연도와 주요 사업 분야는 무엇입니까?   \n",
       "1                    168억 미국 달러는 리브니의 무슨 항목에 해당합니까?   \n",
       "2                    2023년 기준 Rivian의 직원 수는 몇 명입니까?   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  ['Rivian Automotive, Inc.는 2009년에 설립된 미국의 전기 자...   \n",
       "1  ['- **회사 유형:** 상장\\n- **거래소:** NASDAQ: RIVN\\n- ...   \n",
       "2  ['- **총 자본 (2023):** 91억 4천만 미국 달러\\n- **직원 수 (...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Rivian Automotive, Inc.는 2009년에 설립된 미국의 전기 자동차...   \n",
       "1             168억 미국 달러는 2023년 기준 리브니의 총 자산에 해당합니다.   \n",
       "2             2023년 12월 기준 Rivian의 직원 수는 16,790명입니다.   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  single_hop_specifc_query_synthesizer  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_evaluation_dataset(file_path):\n",
    "    \"\"\"\n",
    "    평가 데이터셋 로드\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): 평가 데이터 파일 경로\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: 평가 데이터셋\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"지원하지 않는 파일 형식\")\n",
    "        \n",
    "        print(f\"✅ 평가 데이터셋 로드: {len(df)}개 질문\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 데이터셋 로드 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "# 평가 데이터셋 로드\n",
    "\n",
    "eval_df = load_evaluation_dataset(\"./data/synthetic_testset.csv\")\n",
    "eval_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[질문 1]\n",
      "질문: Rivian Automotive, Inc.의 설립 연도와 주요 사업 분야는 무엇입니까?\n",
      "정답 문서: 1개\n",
      "  [1] 내용: Rivian Automotive, Inc.는 2009년에 설립된 미국의 전기 자동차 제조업...\n",
      "--------------------------------------------------\n",
      "\n",
      "[질문 2]\n",
      "질문: 168억 미국 달러는 리브니의 무슨 항목에 해당합니까?\n",
      "정답 문서: 1개\n",
      "  [1] 내용: - **회사 유형:** 상장\n",
      "- **거래소:** NASDAQ: RIVN\n",
      "- **설립:** ...\n",
      "--------------------------------------------------\n",
      "\n",
      "[질문 3]\n",
      "질문: 2023년 기준 Rivian의 직원 수는 몇 명입니까?\n",
      "정답 문서: 1개\n",
      "  [1] 내용: - **총 자본 (2023):** 91억 4천만 미국 달러\n",
      "- **직원 수 (2023년 1...\n",
      "--------------------------------------------------\n",
      "\n",
      "[질문 1]\n",
      "질문: Tesla의 Bitcoin 투자와 NASDAQ-100 상장, 그리고 2020년 주가 상승은 어떻게 연결되며, 이 세 가지가 Tesla의 전기차 사업 성장에 어떤 영향을 미쳤습니까?\n",
      "정답 문서: 3개\n",
      "  [1] 내용: <1-hop>\n",
      "\n",
      "2021년 초, Tesla는 Bitcoin에 15억 달러를 투자하고 환경 ...\n",
      "  [2] 내용: <2-hop>\n",
      "\n",
      "Tesla는 2012년 6월 Model S 고급 세단을 출시했습니다. Mo...\n",
      "  [3] 내용: <3-hop>\n",
      "\n",
      "2019년 7월부터 2020년 6월까지 Tesla는 4분기 연속 흑자를 보...\n",
      "--------------------------------------------------\n",
      "\n",
      "[질문 2]\n",
      "질문: Tesla의 Autopilot driver assistance system과 향후 출시 예정인 Autonomous driving technology 차량들은 무엇이며, 각각의 특징은 무엇입니까?\n",
      "정답 문서: 2개\n",
      "  [1] 내용: <1-hop>\n",
      "\n",
      "Tesla는 2012년 6월 Model S 고급 세단을 출시했습니다. Mo...\n",
      "  [2] 내용: <2-hop>\n",
      "\n",
      "### 발표된 제품\n",
      "\n",
      "- **Roadster (2세대):** 2017년에 ...\n",
      "--------------------------------------------------\n",
      "\n",
      "[질문 3]\n",
      "질문: Tesla의 Gigafactories에서 Model 3 생산과 관련하여 보고된 근로자 권리 침해 사례는 무엇이며, 이러한 문제들이 Tesla의 전반적인 노동 환경과 어떻게 연결되어 있습니까?\n",
      "정답 문서: 3개\n",
      "  [1] 내용: <1-hop>\n",
      "\n",
      "| 개장 | 이름                | 도시            ...\n",
      "  [2] 내용: <2-hop>\n",
      "\n",
      "2024년 12월, 델라웨어 법원은 부적절한 이사회 승인을 이유로 Elon...\n",
      "  [3] 내용: <3-hop>\n",
      "\n",
      "Tesla는 내부 고발자 보복, 근로자 권리 침해, 안전 결함, 홍보 부족...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def prepare_evaluation_data(df):\n",
    "    \"\"\"\n",
    "    평가 데이터 전처리\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): 원본 데이터프레임\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (질문 리스트, 정답 문서 리스트)\n",
    "    \"\"\"\n",
    "    questions = df['user_input'].tolist()\n",
    "    \n",
    "    # 정답 문서 파싱\n",
    "    reference_contexts = []\n",
    "    for contexts in df['reference_contexts']:\n",
    "        if isinstance(contexts, str):\n",
    "            # 문자열을 리스트로 변환\n",
    "            context_list = eval(contexts)\n",
    "        else:\n",
    "            context_list = contexts\n",
    "        \n",
    "        # Document 객체로 변환\n",
    "        docs = [Document(page_content=ctx) for ctx in context_list]\n",
    "        reference_contexts.append(docs)\n",
    "    \n",
    "    return questions, reference_contexts\n",
    "\n",
    "# 평가 데이터 전처리\n",
    "questions, reference_contexts = prepare_evaluation_data(eval_df)\n",
    "\n",
    "# 평가 데이터 확인\n",
    "for i, (q, refs) in enumerate(zip(questions[:3], reference_contexts[:3])):\n",
    "    print(f\"\\n[질문 {i+1}]\")\n",
    "    print(f\"질문: {q}\")\n",
    "    print(f\"정답 문서: {len(refs)}개\")\n",
    "    for j, ref in enumerate(refs):\n",
    "        print(f\"  [{j+1}] 내용: {ref.page_content[:50]}...\")  # 내용 일부만 출력\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# 평가 데이터 확인\n",
    "for i, (q, refs) in enumerate(zip(questions[-3:], reference_contexts[-3:])):\n",
    "    print(f\"\\n[질문 {i+1}]\")\n",
    "    print(f\"질문: {q}\")\n",
    "    print(f\"정답 문서: {len(refs)}개\")\n",
    "    for j, ref in enumerate(refs):\n",
    "        print(f\"  [{j+1}] 내용: {ref.page_content[:50]}...\")  # 내용 일부만 출력\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Starting similarity-based ranx evaluation | 유사도 기반 ranx 평가 시작\n",
      "   Method | 방법: kiwi_rouge, Threshold | 임계값: 0.8, Mode | 모드: reference_based\n",
      "   📊 Reference-based mode: Will calculate proper recall metrics | 참조 기반 모드: 정확한 재현율 계산\n",
      "\n",
      "🔍 Question | 질문 1: Rivian Automotive, Inc.의 설립 연도와 주요 사업 분야는 무엇입니까?...\n",
      "📊 Reference docs | 참조 문서: 1, Retrieved docs | 검색 문서: 5\n",
      "📊 Similarity matrix shape | 유사도 매트릭스 shape: (1, 5)\n",
      "📈 Max similarity | 최대 유사도: 0.800\n",
      "📋 Qrels items | qrels 항목 수: 1\n",
      "📋 Run items | run 항목 수: 5\n",
      "📋 Reference docs found | 참조 문서 발견: 1/1\n",
      "📋 False positives | 거짓 긍정: 4/5\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Question | 질문 2: 168억 미국 달러는 리브니의 무슨 항목에 해당합니까?...\n",
      "📊 Reference docs | 참조 문서: 1, Retrieved docs | 검색 문서: 5\n",
      "📊 Similarity matrix shape | 유사도 매트릭스 shape: (1, 5)\n",
      "📈 Max similarity | 최대 유사도: 0.930\n",
      "📋 Qrels items | qrels 항목 수: 1\n",
      "📋 Run items | run 항목 수: 5\n",
      "📋 Reference docs found | 참조 문서 발견: 1/1\n",
      "📋 False positives | 거짓 긍정: 4/5\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Question | 질문 3: 2023년 기준 Rivian의 직원 수는 몇 명입니까?...\n",
      "📊 Reference docs | 참조 문서: 1, Retrieved docs | 검색 문서: 5\n",
      "📊 Similarity matrix shape | 유사도 매트릭스 shape: (1, 5)\n",
      "📈 Max similarity | 최대 유사도: 0.683\n",
      "📋 Qrels items | qrels 항목 수: 1\n",
      "📋 Run items | run 항목 수: 5\n",
      "📋 Reference docs found | 참조 문서 발견: 0/1\n",
      "📋 False positives | 거짓 긍정: 5/5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ranx similarity evaluation | ranx 유사도 평가: 100%|██████████| 50/50 [00:19<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Similarity-based ranx evaluation results | 유사도 기반 ranx 평가 결과 (kiwi_rouge):\n",
      "  hit_rate@5: 0.860\n",
      "  ndcg@5: 0.749\n",
      "  map@5: 0.702\n",
      "  mrr: 0.718\n",
      "\n",
      "📈 Analysis information | 분석 정보:\n",
      "  Total queries | 총 질문 수: 50\n",
      "  Total retrieved docs | 총 검색 문서 수: 250\n",
      "  Avg docs per query | 질문당 평균 검색 문서: 5.0\n",
      "  Total relevant docs | 관련 문서 총 개수: 76\n",
      "  Avg relevant per query | 질문당 평균 관련 문서: 1.5\n",
      "  Threshold used | 사용된 임계값: 0.8\n",
      "  Overall recall | 전체 재현율: 0.789 (60/76)\n"
     ]
    }
   ],
   "source": [
    "# ranx-k 라이브러리 사용해서 검색 결과 평가\n",
    "from ranx_k.evaluation import evaluate_with_ranx_similarity\n",
    "\n",
    "# ranx-k 평가 실행 (rouge 점수가 높은 경우) -> 문자열 유사도 기반 평가\n",
    "base_results = evaluate_with_ranx_similarity(\n",
    "    retriever=base_retriever,\n",
    "    questions=questions, \n",
    "    reference_contexts=reference_contexts,\n",
    "    k=5,\n",
    "    method='kiwi_rouge',  \n",
    "    similarity_threshold=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Starting similarity-based ranx evaluation | 유사도 기반 ranx 평가 시작\n",
      "   Method | 방법: kiwi_rouge, Threshold | 임계값: 0.8, Mode | 모드: reference_based\n",
      "   📊 Reference-based mode: Will calculate proper recall metrics | 참조 기반 모드: 정확한 재현율 계산\n",
      "\n",
      "🔍 Question | 질문 1: Rivian Automotive, Inc.의 설립 연도와 주요 사업 분야는 무엇입니까?...\n",
      "📊 Reference docs | 참조 문서: 1, Retrieved docs | 검색 문서: 5\n",
      "📊 Similarity matrix shape | 유사도 매트릭스 shape: (1, 5)\n",
      "📈 Max similarity | 최대 유사도: 0.800\n",
      "📋 Qrels items | qrels 항목 수: 1\n",
      "📋 Run items | run 항목 수: 5\n",
      "📋 Reference docs found | 참조 문서 발견: 1/1\n",
      "📋 False positives | 거짓 긍정: 4/5\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Question | 질문 2: 168억 미국 달러는 리브니의 무슨 항목에 해당합니까?...\n",
      "📊 Reference docs | 참조 문서: 1, Retrieved docs | 검색 문서: 5\n",
      "📊 Similarity matrix shape | 유사도 매트릭스 shape: (1, 5)\n",
      "📈 Max similarity | 최대 유사도: 0.930\n",
      "📋 Qrels items | qrels 항목 수: 1\n",
      "📋 Run items | run 항목 수: 5\n",
      "📋 Reference docs found | 참조 문서 발견: 1/1\n",
      "📋 False positives | 거짓 긍정: 4/5\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Question | 질문 3: 2023년 기준 Rivian의 직원 수는 몇 명입니까?...\n",
      "📊 Reference docs | 참조 문서: 1, Retrieved docs | 검색 문서: 5\n",
      "📊 Similarity matrix shape | 유사도 매트릭스 shape: (1, 5)\n",
      "📈 Max similarity | 최대 유사도: 0.683\n",
      "📋 Qrels items | qrels 항목 수: 1\n",
      "📋 Run items | run 항목 수: 5\n",
      "📋 Reference docs found | 참조 문서 발견: 0/1\n",
      "📋 False positives | 거짓 긍정: 5/5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ranx similarity evaluation | ranx 유사도 평가: 100%|██████████| 50/50 [01:47<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Similarity-based ranx evaluation results | 유사도 기반 ranx 평가 결과 (kiwi_rouge):\n",
      "  hit_rate@5: 0.860\n",
      "  ndcg@5: 0.822\n",
      "  map@5: 0.802\n",
      "  mrr: 0.822\n",
      "\n",
      "📈 Analysis information | 분석 정보:\n",
      "  Total queries | 총 질문 수: 50\n",
      "  Total retrieved docs | 총 검색 문서 수: 250\n",
      "  Avg docs per query | 질문당 평균 검색 문서: 5.0\n",
      "  Total relevant docs | 관련 문서 총 개수: 76\n",
      "  Avg relevant per query | 질문당 평균 관련 문서: 1.5\n",
      "  Threshold used | 사용된 임계값: 0.8\n",
      "  Overall recall | 전체 재현율: 0.789 (60/76)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rerank_results = evaluate_with_ranx_similarity(\n",
    "    retriever=cross_encoder_retriever,\n",
    "    questions=questions, \n",
    "    reference_contexts=reference_contexts,\n",
    "    k=5,\n",
    "    method='kiwi_rouge',  \n",
    "    similarity_threshold=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 LLM 기반 재순위화\n",
    "\n",
    "- **대규모 언어 모델**을 활용하여 검색 결과의 재순위화를 수행함\n",
    "- 쿼리와 문서 간의 **관련성 분석**을 통해 최적의 순서를 도출함\n",
    "- **LLMListwiseRerank**와 같은 전문화된 재순위화 모델을 적용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_reranker(model_name=\"gpt-4.1-mini\", top_n=5):\n",
    "    \"\"\"\n",
    "    LLM 기반 재순위화 시스템 생성\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): 사용할 LLM 모델\n",
    "        top_n (int): 반환할 상위 문서 수\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: LLM 재순위화 검색기\n",
    "    \"\"\"\n",
    "    print(f\"🤖 LLM 재순위화 시스템 초기화\")\n",
    "    print(f\"   모델: {model_name}\")\n",
    "    print(f\"   상위 {top_n}개 문서 반환\")\n",
    "    \n",
    "    try:\n",
    "        # LLM 초기화\n",
    "        llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "        \n",
    "        # LLM 기반 재순위화 컴프레서 생성\n",
    "        llm_reranker = LLMListwiseRerank.from_llm(llm, top_n=top_n)\n",
    "        \n",
    "        # 컨텍스트 압축 검색기 생성\n",
    "        llm_compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=llm_reranker,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ LLM 재순위화 시스템 생성 완료\")\n",
    "        return llm_compression_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ LLM 재순위화 초기화 실패: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 LLM 재순위화 시스템 초기화\n",
      "   모델: gpt-4.1-mini\n",
      "   상위 3개 문서 반환\n",
      "✅ LLM 재순위화 시스템 생성 완료\n",
      "\n",
      "🤖 LLM 재순위화 검색 결과:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "<Document>\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다.\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "<Document>\n",
      "- **Model Y:** 싱글 모터, 후륜 구동 또는 듀얼 모터, 전륜 구동 레이아웃을 갖춘 5인승 및 7인승 구성으로 제공되는 중형 크로스오버 SUV. 이 차량은 고급 Model X SUV보다 저렴하도록 설계되었습니다. Model Y 프로토타입은 2019년 3월에 처음 공개되었으며 배송은 2020년 3월에 시작되었습니다.\n",
      "- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다.\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "<Document>\n",
      "| Tesla 모델 |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| 이름       | 제조년도 | 좌석  | 참고             |\n",
      "| Roadster   | 2008     | 2     | 2012년에 단종    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025년 출시 예정 |\n",
      "| Cybercab   |          | 2     | 2026년 출시 예정 |\n",
      "| Robovan    |          | 20    | 명시된 기간 없음 |\n",
      "\n",
      "### 사용 가능한 제품\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LLM 재순위화 시스템 생성\n",
    "llm_retriever = create_llm_reranker(top_n=3)\n",
    "\n",
    "# LLM 재순위화 검색기 사용하여 검색\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = llm_retriever.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"\\n🤖 LLM 재순위화 검색 결과:\")\n",
    "print(\"-\"*200)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 맥락 압축(Contextual Compression) 기법\n",
    "\n",
    "### 4.1 맥락 압축의 핵심 개념\n",
    "\n",
    "맥락 압축은 검색된 문서에서 쿼리와 관련된 핵심 정보만을 선별적으로 추출하는 기법입니다.\n",
    "\n",
    "#### 🎯 **맥락 압축의 이점**\n",
    "\n",
    "1. **비용 절감**: 불필요한 토큰 제거로 LLM API 비용 절약\n",
    "2. **성능 향상**: 핵심 정보만 제공하여 답변 품질 향상\n",
    "3. **노이즈 제거**: 관련 없는 정보 필터링\n",
    "4. **컨텍스트 효율성**: 제한된 컨텍스트 윈도우 최적 활용\n",
    "\n",
    "### 4.2 LLM 기반 필터링\n",
    "\n",
    "#### 4.2.1 LLMChainFilter 구현\n",
    "\n",
    "\n",
    "- **LLM 기반 필터링**으로 검색된 문서의 포함 여부를 결정함\n",
    "- **원본 유지 방식**으로 문서 내용의 변경 없이 선별 작업을 수행함\n",
    "- **선택적 필터링**을 통해 관련성 높은 문서만을 최종 반환함\n",
    "- 문서 원본을 보존하면서 관련성 기반의 스마트한 선별을 수행하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_filter(model_name=\"gpt-4.1-mini\"):\n",
    "    \"\"\"\n",
    "    LLM 기반 문서 필터링 시스템 생성\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): 사용할 LLM 모델\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: LLM 필터링 검색기\n",
    "    \"\"\"\n",
    "    print(f\"🔍 LLM 문서 필터링 시스템 초기화\")\n",
    "    print(f\"   모델: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        # LLM 초기화\n",
    "        llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "        \n",
    "        # LLM 체인 필터 생성\n",
    "        llm_filter = LLMChainFilter.from_llm(llm)\n",
    "        \n",
    "        # 컨텍스트 압축 검색기 생성\n",
    "        filter_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=llm_filter,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ LLM 필터링 시스템 생성 완료\")\n",
    "        return filter_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ LLM 필터링 초기화 실패: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 LLM 문서 필터링 시스템 초기화\n",
      "   모델: gpt-4.1-mini\n",
      "✅ LLM 필터링 시스템 생성 완료\n",
      "\n",
      "🔍 LLM 필터링 검색 결과:\n",
      "<Document>\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다.\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "<Document>\n",
      "- **Model Y:** 싱글 모터, 후륜 구동 또는 듀얼 모터, 전륜 구동 레이아웃을 갖춘 5인승 및 7인승 구성으로 제공되는 중형 크로스오버 SUV. 이 차량은 고급 Model X SUV보다 저렴하도록 설계되었습니다. Model Y 프로토타입은 2019년 3월에 처음 공개되었으며 배송은 2020년 3월에 시작되었습니다.\n",
      "- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다.\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "<Document>\n",
      "| Tesla 모델 |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| 이름       | 제조년도 | 좌석  | 참고             |\n",
      "| Roadster   | 2008     | 2     | 2012년에 단종    |\n",
      "| Model S    | 2012     | 5/7   |                  |\n",
      "| Model X    | 2015     | 5/6/7 |                  |\n",
      "| Model 3    | 2017     | 5     |                  |\n",
      "| Model Y    | 2020     | 5/7   |                  |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  |\n",
      "| Roadster 2 |          | 2/4   | 2025년 출시 예정 |\n",
      "| Cybercab   |          | 2     | 2026년 출시 예정 |\n",
      "| Robovan    |          | 20    | 명시된 기간 없음 |\n",
      "\n",
      "### 사용 가능한 제품\n",
      "</Document>\n",
      "<Source>이 문서는 'unknown'에 대한 문서입니다.</Source> [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LLM 필터링 시스템 생성\n",
    "filter_retriever = create_llm_filter()\n",
    "\n",
    "# LLM 필터링 검색기 사용하여 검색\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = filter_retriever.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"\\n🔍 LLM 필터링 검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 LLMChainExtractor 구현 (추출요약)\n",
    "\n",
    "- **LLM 기반 추출**로 문서에서 쿼리 관련 핵심 내용만을 선별함\n",
    "- **순차적 처리 방식**으로 각 문서를 검토하여 관련 정보를 추출함\n",
    "- **맞춤형 요약**을 통해 쿼리에 최적화된 압축 결과를 생성함\n",
    "- 쿼리 맥락에 따른 선별적 정보 추출로 효율적인 문서 압축을 실현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_extractor(model_name=\"gpt-4.1-mini\"):\n",
    "    \"\"\"\n",
    "    LLM 기반 정보 *추출* 시스템 생성\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): 사용할 LLM 모델\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: LLM 추출 검색기\n",
    "    \"\"\"\n",
    "    print(f\"📝 LLM 정보 추출 시스템 초기화\")\n",
    "    print(f\"   모델: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        # LLM 초기화\n",
    "        llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "        \n",
    "        # LLM 체인 추출기 생성\n",
    "        llm_extractor = LLMChainExtractor.from_llm(llm)\n",
    "        \n",
    "        # 컨텍스트 압축 검색기 생성\n",
    "        extractor_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=llm_extractor,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ LLM 추출 시스템 생성 완료\")\n",
    "        return extractor_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ LLM 추출 초기화 실패: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 LLM 정보 추출 시스템 초기화\n",
      "   모델: gpt-4.1-mini\n",
      "✅ LLM 추출 시스템 생성 완료\n",
      "\n",
      "📝 LLM 추출 검색 결과:\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트리 모터 전륜 구동의 세 가지 모델이 제공됩니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "- **Tesla Semi:** Tesla Semi는 Tesla, Inc.의 클래스 8 세미 트럭으로, 트리 모터, 후륜 구동 레이아웃을 갖추고 있습니다. Tesla는 Semi가 일반적인 디젤 세미 트럭보다 약 3배 더 강력하고 주행 거리가 500마일(800km)이라고 주장합니다. 초기 배송은 2022년 12월 1일에 PepsiCo에 이루어졌습니다. [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n",
      "| Tesla 모델 |          |       |                  |\n",
      "| :--------- | :------- | :---- | :--------------- |\n",
      "| Semi       | 2022     | 2     |                  |\n",
      "| Cybertruck | 2023     | 5     |                  | [출처: data\\테슬라_KR.md]\n",
      "========================================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LLM 추출 시스템 생성\n",
    "extractor_retriever = create_llm_extractor()\n",
    "\n",
    "# LLM 추출 검색기 사용하여 검색\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = extractor_retriever.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"\\n📝 LLM 추출 검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 임베딩 기반 필터링 (EmbeddingsFilter)\n",
    "\n",
    "- **임베딩 기반 필터링**으로 문서와 쿼리 간 유사도를 계산함\n",
    "- **LLM 미사용 방식**으로 빠른 처리 속도와 비용 효율성을 확보함 (LLM 호출보다 저렴하고 빠른 옵션)\n",
    "- **유사도 기준 선별**을 통해 관련성 높은 문서만을 효과적으로 추출함\n",
    "- 경제적이고 신속한 임베딩 기반의 문서 필터링 기법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_filter(similarity_threshold=0.1):\n",
    "    \"\"\"\n",
    "    임베딩 기반 유사도 필터링 시스템 생성\n",
    "    \n",
    "    Args:\n",
    "        similarity_threshold (float): 유사도 임계값 (0~1)\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: 임베딩 필터링 검색기\n",
    "    \"\"\"\n",
    "    print(f\"🧮 임베딩 기반 필터링 시스템 초기화\")\n",
    "    print(f\"   유사도 임계값: {similarity_threshold}\")\n",
    "    \n",
    "    try:\n",
    "        # 임베딩 모델 초기화\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        \n",
    "        # 임베딩 필터 생성\n",
    "        embeddings_filter = EmbeddingsFilter(\n",
    "            embeddings=embeddings, \n",
    "            similarity_threshold=similarity_threshold\n",
    "        )\n",
    "        \n",
    "        # 컨텍스트 압축 검색기 생성\n",
    "        embedding_filter_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=embeddings_filter,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ 임베딩 필터링 시스템 생성 완료\")\n",
    "        return embedding_filter_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 임베딩 필터링 초기화 실패: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧮 임베딩 필터 임계값별 성능 테스트\n",
      "================================================================================\n",
      "테스트 질문: 테슬라 트럭 모델이 있나요?\n",
      "\n",
      "🔍 임계값 0.2 테스트:\n",
      "🧮 임베딩 기반 필터링 시스템 초기화\n",
      "   유사도 임계값: 0.2\n",
      "✅ 임베딩 필터링 시스템 생성 완료\n",
      "   ✅ 필터링된 문서 수: 5개\n",
      "   ⏱️ 처리 시간: 1.591초\n",
      "   📄 상위 결과: <Document>\n",
      "- **Cybertruck:** 2019년 11월에 처음 발표된 풀사이즈 픽업 트럭. 후륜 구동, 듀얼 모터 전륜 구동, 트...\n",
      "--------------------------------------------------\n",
      "🔍 임계값 0.4 테스트:\n",
      "🧮 임베딩 기반 필터링 시스템 초기화\n",
      "   유사도 임계값: 0.4\n",
      "✅ 임베딩 필터링 시스템 생성 완료\n",
      "   ✅ 필터링된 문서 수: 0개\n",
      "   ⏱️ 처리 시간: 1.685초\n",
      "   ❌ 임계값 조건을 만족하는 문서 없음\n",
      "--------------------------------------------------\n",
      "🔍 임계값 0.6 테스트:\n",
      "🧮 임베딩 기반 필터링 시스템 초기화\n",
      "   유사도 임계값: 0.6\n",
      "✅ 임베딩 필터링 시스템 생성 완료\n",
      "   ✅ 필터링된 문서 수: 0개\n",
      "   ⏱️ 처리 시간: 4.323초\n",
      "   ❌ 임계값 조건을 만족하는 문서 없음\n",
      "--------------------------------------------------\n",
      "🔍 임계값 0.8 테스트:\n",
      "🧮 임베딩 기반 필터링 시스템 초기화\n",
      "   유사도 임계값: 0.8\n",
      "✅ 임베딩 필터링 시스템 생성 완료\n",
      "   ✅ 필터링된 문서 수: 0개\n",
      "   ⏱️ 처리 시간: 1.334초\n",
      "   ❌ 임계값 조건을 만족하는 문서 없음\n",
      "--------------------------------------------------\n",
      "\n",
      "📊 임계값별 결과 요약:\n",
      "           filtered_count  processing_time\n",
      "Threshold                                 \n",
      "0.2                   5.0            1.591\n",
      "0.4                   0.0            1.685\n",
      "0.6                   0.0            4.323\n",
      "0.8                   0.0            1.334\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_embeddings_filter_thresholds():\n",
    "    \"\"\"다양한 임계값에서 임베딩 필터 성능 테스트\"\"\"\n",
    "    if not base_retriever:\n",
    "        print(\"❌ 기본 검색기가 초기화되지 않았습니다.\")\n",
    "        return\n",
    "    \n",
    "    print(\"🧮 임베딩 필터 임계값별 성능 테스트\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 다양한 임계값 설정\n",
    "    thresholds = [0.2, 0.4, 0.6, 0.8]\n",
    "    test_query = \"테슬라 트럭 모델이 있나요?\"\n",
    "    \n",
    "    print(f\"테스트 질문: {test_query}\\n\")\n",
    "    \n",
    "    threshold_results = {}\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        print(f\"🔍 임계값 {threshold} 테스트:\")\n",
    "        \n",
    "        try:\n",
    "            # 임베딩 필터 생성\n",
    "            filter_retriever = create_embeddings_filter(\n",
    "                similarity_threshold=threshold\n",
    "            )\n",
    "            \n",
    "            if filter_retriever:\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # 필터링 실행\n",
    "                filtered_docs = filter_retriever.invoke(test_query)\n",
    "                \n",
    "                end_time = time.time()\n",
    "                processing_time = end_time - start_time\n",
    "                \n",
    "                threshold_results[threshold] = {\n",
    "                    \"filtered_count\": len(filtered_docs),\n",
    "                    \"processing_time\": processing_time\n",
    "                }\n",
    "                \n",
    "                print(f\"   ✅ 필터링된 문서 수: {len(filtered_docs)}개\")\n",
    "                print(f\"   ⏱️ 처리 시간: {processing_time:.3f}초\")\n",
    "                \n",
    "                # 상위 결과 미리보기\n",
    "                if filtered_docs:\n",
    "                    print(f\"   📄 상위 결과: {filtered_docs[0].page_content[:80]}...\")\n",
    "                else:\n",
    "                    print(\"   ❌ 임계값 조건을 만족하는 문서 없음\")\n",
    "            else:\n",
    "                print(\"   ❌ 필터 생성 실패\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ 오류 발생: {e}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # 결과 시각화\n",
    "    if threshold_results:\n",
    "        print(\"\\n📊 임계값별 결과 요약:\")\n",
    "        \n",
    "        # DataFrame 생성\n",
    "        df = pd.DataFrame(threshold_results).T\n",
    "        df.index.name = 'Threshold'\n",
    "        df = df.round(3)\n",
    "        print(df.to_string())\n",
    "        \n",
    "        # 시각화\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # 필터링된 문서 수\n",
    "        ax1.bar(df.index, df['filtered_count'], color='skyblue')\n",
    "        ax1.set_title('임계값별 필터링된 문서 수')\n",
    "        ax1.set_xlabel('유사도 임계값')\n",
    "        ax1.set_ylabel('문서 수')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 처리 시간\n",
    "        ax2.bar(df.index, df['processing_time'], color='lightcoral')\n",
    "        ax2.set_title('임계값별 처리 시간')\n",
    "        ax2.set_xlabel('유사도 임계값')\n",
    "        ax2.set_ylabel('처리 시간 (초)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return threshold_results\n",
    "\n",
    "# 임베딩 필터 임계값 테스트\n",
    "threshold_test_results = test_embeddings_filter_thresholds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 파이프라인 최적화 (DocumentCompressorPipeline)\n",
    "\n",
    "여러 압축 기법을 순차적으로 연결하여 최적의 결과를 얻는 방법입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "\n",
    "\n",
    "def create_comprehensive_pipeline():\n",
    "    \"\"\"\n",
    "    포괄적인 문서 압축 파이프라인 생성\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: 다단계 압축 검색기\n",
    "    \"\"\"\n",
    "    print(\"🔧 포괄적인 문서 압축 파이프라인 구성\")\n",
    "    \n",
    "    try:\n",
    "        # 임베딩 모델 초기화\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        \n",
    "        # LLM 초기화\n",
    "        llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "        \n",
    "        # 파이프라인 구성 요소들\n",
    "        print(\"   1️⃣ 중복 제거 필터 추가\")\n",
    "        redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "        \n",
    "        print(\"   2️⃣ 유사도 기반 필터 추가 (임계값: 0.4)\")\n",
    "        similarity_filter = EmbeddingsFilter(\n",
    "            embeddings=embeddings, \n",
    "            similarity_threshold=0.4\n",
    "        )\n",
    "        \n",
    "        print(\"   3️⃣ LLM 기반 재순위화 추가\")\n",
    "        llm_reranker = LLMListwiseRerank.from_llm(llm, top_n=5)\n",
    "        \n",
    "        # 파이프라인 생성\n",
    "        pipeline_compressor = DocumentCompressorPipeline(\n",
    "            transformers=[\n",
    "                redundant_filter,    # 1단계: 중복 제거\n",
    "                similarity_filter,   # 2단계: 유사도 필터링\n",
    "                llm_reranker        # 3단계: LLM 재순위화\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # 최종 압축 검색기 생성\n",
    "        pipeline_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=pipeline_compressor,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ 포괄적인 압축 파이프라인 생성 완료\")\n",
    "        return pipeline_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 파이프라인 생성 실패: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 포괄적인 문서 압축 파이프라인 구성\n",
      "   1️⃣ 중복 제거 필터 추가\n",
      "   2️⃣ 유사도 기반 필터 추가 (임계값: 0.4)\n",
      "   3️⃣ LLM 기반 재순위화 추가\n",
      "✅ 포괄적인 압축 파이프라인 생성 완료\n",
      "\n",
      "🔄 포괄적인 문서 압축 파이프라인 검색 결과:\n",
      "   필터링된 문서 수: 0개\n"
     ]
    }
   ],
   "source": [
    "# 파이프라인 생성\n",
    "pipeline_retriever = create_comprehensive_pipeline()\n",
    "\n",
    "# 파이프라인 검색기 사용하여 검색\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = pipeline_retriever.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"\\n🔄 포괄적인 문서 압축 파이프라인 검색 결과:\")\n",
    "print(f\"   필터링된 문서 수: {len(retrieved_docs)}개\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정리\n",
    "\n",
    "\n",
    "\n",
    "재순위화 / 맥락 압축\n",
    "> 검색을 하고 끝나는게 아니라, 답변의 퀄리티를 더 향상 시키기 위해서 실행하는 것\n",
    "> 재순위화 : 관련성 있는 것을 앞으로 배치 (거의 필수적인 작업)\n",
    "> 맥락 압축 : 불필요 내용 제거\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## 사전 준비 ########  ::: 백터 저장소 및 기본 검색기 설정\n",
    "\n",
    "def initialize_vector_store(embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\"), collection_name=\"hybrid_search_db\", persist_directory = \"./local_chroma_db\"):\n",
    "    \"\"\"\n",
    "    기존 벡터 저장소를 로드하거나 새로 생성\n",
    "    \n",
    "    Returns:\n",
    "        Chroma: 벡터 저장소 객체\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        # 기존 벡터 저장소 로드 시도     \n",
    "        vector_store = Chroma( \n",
    "            collection_name=collection_name, \n",
    "            embedding_function=embeddings,\n",
    "            persist_directory=persist_directory,\n",
    "        )   \n",
    "        \n",
    "        doc_count = vector_store._collection.count() # 저장소 내 문서 개수 확인\n",
    "        if doc_count > 0:\n",
    "            print(f\"✅ 기존 벡터 저장소 로드: {doc_count}개 문서\")\n",
    "            return vector_store\n",
    "        else:\n",
    "            print(\"⚠️ 빈 벡터 저장소입니다. 데이터를 추가해주세요.\")\n",
    "            return vector_store\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 벡터 저장소 로드 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "# 벡터 저장소 초기화\n",
    "vector_store = initialize_vector_store() \n",
    "\n",
    "if vector_store:\n",
    "    # 기본 검색기 생성\n",
    "    base_retriever = vector_store.as_retriever(search_kwargs={\"k\": 5}) # 유사도 상위 5개 문서 검색\n",
    "    print(\"✅ 기본 검색기 생성 완료\")\n",
    "\n",
    "\n",
    "######## 사전 준비 ########  ::: 평가 데이터셋 로드 및 전처리\n",
    "\n",
    "def load_evaluation_dataset(file_path):\n",
    "    \"\"\"\n",
    "    평가 데이터셋 로드\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): 평가 데이터 파일 경로\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: 평가 데이터셋\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"지원하지 않는 파일 형식\")\n",
    "        \n",
    "        print(f\"✅ 평가 데이터셋 로드: {len(df)}개 질문\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 데이터셋 로드 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def prepare_evaluation_data(df):\n",
    "    \"\"\"\n",
    "    평가 데이터 전처리\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): 원본 데이터프레임\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (질문 리스트, 정답 문서 리스트)\n",
    "    \"\"\"\n",
    "    questions = df['user_input'].tolist()\n",
    "    \n",
    "    # 정답 문서 파싱\n",
    "    reference_contexts = []\n",
    "    for contexts in df['reference_contexts']:\n",
    "        if isinstance(contexts, str):\n",
    "            # 문자열을 리스트로 변환\n",
    "            context_list = eval(contexts)\n",
    "        else:\n",
    "            context_list = contexts\n",
    "        \n",
    "        # Document 객체로 변환\n",
    "        docs = [Document(page_content=ctx) for ctx in context_list]\n",
    "        reference_contexts.append(docs)\n",
    "    \n",
    "    return questions, reference_contexts\n",
    "\n",
    "# 평가 데이터셋 로드\n",
    "eval_df = load_evaluation_dataset(\"./data/synthetic_testset.csv\")\n",
    "\n",
    "# 평가 데이터 전처리\n",
    "questions, reference_contexts = prepare_evaluation_data(eval_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## 재순위화 ########\n",
    "\n",
    "# 재순위화 시스템 생성\n",
    "\n",
    "# 1. Cross-Encoder 재순위화 시스템 생성\n",
    "def create_cross_encoder_reranker(model_name=\"BAAI/bge-reranker-v2-m3\", top_n=5):\n",
    "    \"\"\"\n",
    "    Cross-Encoder 재순위화 시스템 생성\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): 사용할 Cross-Encoder 모델\n",
    "        top_n (int): 반환할 상위 문서 수\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: 재순위화 검색기\n",
    "    \"\"\"\n",
    "    print(f\"🔄 Cross-Encoder 재순위화 시스템 초기화\")\n",
    "    print(f\"   모델: {model_name}\")\n",
    "    print(f\"   상위 {top_n}개 문서 반환\")\n",
    "    \n",
    "    try:\n",
    "        # Cross-Encoder 모델 로드\n",
    "        cross_encoder_model = HuggingFaceCrossEncoder(model_name=model_name)\n",
    "        \n",
    "        # 재순위화 컴프레서 생성\n",
    "        reranker = CrossEncoderReranker(\n",
    "            model=cross_encoder_model, \n",
    "            top_n=top_n\n",
    "        )\n",
    "        \n",
    "        # 컨텍스트 압축 검색기 생성\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=reranker,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Cross-Encoder 재순위화 시스템 생성 완료\")\n",
    "        return compression_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Cross-Encoder 초기화 실패: {e}\")\n",
    "        return None\n",
    "cross_encoder_retriever = create_cross_encoder_reranker(top_n=5)\n",
    "\n",
    "# CrossEncoderReranker를 사용한 retriever를 사용하여 검색\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = cross_encoder_retriever.invoke(query) \n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"\\n🔄 Cross-Encoder 재순위화 검색 결과:\")\n",
    "print(\"-\"*200)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)\n",
    "\n",
    "\n",
    "\n",
    "# 2. LLM 재순위화 시스템 생성\n",
    "def create_llm_reranker(model_name=\"gpt-4.1-mini\", top_n=5):\n",
    "    \"\"\"\n",
    "    LLM 기반 재순위화 시스템 생성\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): 사용할 LLM 모델\n",
    "        top_n (int): 반환할 상위 문서 수\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: LLM 재순위화 검색기\n",
    "    \"\"\"\n",
    "    print(f\"🤖 LLM 재순위화 시스템 초기화\")\n",
    "    print(f\"   모델: {model_name}\")\n",
    "    print(f\"   상위 {top_n}개 문서 반환\")\n",
    "    \n",
    "    try:\n",
    "        # LLM 초기화\n",
    "        llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "        \n",
    "        # LLM 기반 재순위화 컴프레서 생성\n",
    "        llm_reranker = LLMListwiseRerank.from_llm(llm, top_n=top_n)\n",
    "        \n",
    "        # 컨텍스트 압축 검색기 생성\n",
    "        llm_compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=llm_reranker,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ LLM 재순위화 시스템 생성 완료\")\n",
    "        return llm_compression_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ LLM 재순위화 초기화 실패: {e}\")\n",
    "        return None\n",
    "llm_retriever = create_llm_reranker(top_n=3)\n",
    "\n",
    "# LLM 재순위화 검색기 사용하여 검색\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = llm_retriever.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"\\n🤖 LLM 재순위화 검색 결과:\")\n",
    "print(\"-\"*200)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맥락 압축 \n",
    "\n",
    "\n",
    "# 3. LLM \"필터링\" 시스템 생성\n",
    "def create_llm_filter(model_name=\"gpt-4.1-mini\"):\n",
    "    \"\"\"\n",
    "    LLM 기반 문서 필터링 시스템 생성\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): 사용할 LLM 모델\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: LLM 필터링 검색기\n",
    "    \"\"\"\n",
    "    print(f\"🔍 LLM 문서 필터링 시스템 초기화\")\n",
    "    print(f\"   모델: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        # LLM 초기화\n",
    "        llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "        \n",
    "        # LLM 체인 필터 생성\n",
    "        llm_filter = LLMChainFilter.from_llm(llm)\n",
    "        \n",
    "        # 컨텍스트 압축 검색기 생성\n",
    "        filter_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=llm_filter,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ LLM 필터링 시스템 생성 완료\")\n",
    "        return filter_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ LLM 필터링 초기화 실패: {e}\")\n",
    "        return None\n",
    "filter_retriever = create_llm_filter()\n",
    "\n",
    "# LLM 필터링 검색기 사용하여 검색\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = filter_retriever.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"\\n🔍 LLM 필터링 검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)\n",
    "\n",
    "\n",
    "# 4. LLM \"추출\" 시스템 생성\n",
    "def create_llm_extractor(model_name=\"gpt-4.1-mini\"):\n",
    "    \"\"\"\n",
    "    LLM 기반 정보 *추출* 시스템 생성\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): 사용할 LLM 모델\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: LLM 추출 검색기\n",
    "    \"\"\"\n",
    "    print(f\"📝 LLM 정보 추출 시스템 초기화\")\n",
    "    print(f\"   모델: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        # LLM 초기화\n",
    "        llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "        \n",
    "        # LLM 체인 추출기 생성\n",
    "        llm_extractor = LLMChainExtractor.from_llm(llm)\n",
    "        \n",
    "        # 컨텍스트 압축 검색기 생성\n",
    "        extractor_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=llm_extractor,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ LLM 추출 시스템 생성 완료\")\n",
    "        return extractor_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ LLM 추출 초기화 실패: {e}\")\n",
    "        return None\n",
    "extractor_retriever = create_llm_extractor()\n",
    "\n",
    "# LLM 추출 검색기 사용하여 검색\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = extractor_retriever.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"\\n📝 LLM 추출 검색 결과:\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)\n",
    "\n",
    "\n",
    "\n",
    "# 5. 임베딩 기반 \"필터링\" 시스템 생성\n",
    "\n",
    "def create_embeddings_filter(similarity_threshold=0.1):\n",
    "    \"\"\"\n",
    "    임베딩 기반 유사도 필터링 시스템 생성\n",
    "    \n",
    "    Args:\n",
    "        similarity_threshold (float): 유사도 임계값 (0~1)\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: 임베딩 필터링 검색기\n",
    "    \"\"\"\n",
    "    print(f\"🧮 임베딩 기반 필터링 시스템 초기화\")\n",
    "    print(f\"   유사도 임계값: {similarity_threshold}\")\n",
    "    \n",
    "    try:\n",
    "        # 임베딩 모델 초기화\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        \n",
    "        # 임베딩 필터 생성\n",
    "        embeddings_filter = EmbeddingsFilter(\n",
    "            embeddings=embeddings, \n",
    "            similarity_threshold=similarity_threshold\n",
    "        )\n",
    "        \n",
    "        # 컨텍스트 압축 검색기 생성\n",
    "        embedding_filter_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=embeddings_filter,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ 임베딩 필터링 시스템 생성 완료\")\n",
    "        return embedding_filter_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 임베딩 필터링 초기화 실패: {e}\")\n",
    "        return None\n",
    "\n",
    "def test_embeddings_filter_thresholds():\n",
    "    \"\"\"다양한 임계값에서 임베딩 필터 성능 테스트\"\"\"\n",
    "    if not base_retriever:\n",
    "        print(\"❌ 기본 검색기가 초기화되지 않았습니다.\")\n",
    "        return\n",
    "    \n",
    "    print(\"🧮 임베딩 필터 임계값별 성능 테스트\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 다양한 임계값 설정\n",
    "    thresholds = [0.2, 0.4, 0.6, 0.8]\n",
    "    test_query = \"테슬라 트럭 모델이 있나요?\"\n",
    "    \n",
    "    print(f\"테스트 질문: {test_query}\\n\")\n",
    "    \n",
    "    threshold_results = {}\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        print(f\"🔍 임계값 {threshold} 테스트:\")\n",
    "        \n",
    "        try:\n",
    "            # 임베딩 필터 생성\n",
    "            filter_retriever = create_embeddings_filter(\n",
    "                similarity_threshold=threshold\n",
    "            )\n",
    "            \n",
    "            if filter_retriever:\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # 필터링 실행\n",
    "                filtered_docs = filter_retriever.invoke(test_query)\n",
    "                \n",
    "                end_time = time.time()\n",
    "                processing_time = end_time - start_time\n",
    "                \n",
    "                threshold_results[threshold] = {\n",
    "                    \"filtered_count\": len(filtered_docs),\n",
    "                    \"processing_time\": processing_time\n",
    "                }\n",
    "                \n",
    "                print(f\"   ✅ 필터링된 문서 수: {len(filtered_docs)}개\")\n",
    "                print(f\"   ⏱️ 처리 시간: {processing_time:.3f}초\")\n",
    "                \n",
    "                # 상위 결과 미리보기\n",
    "                if filtered_docs:\n",
    "                    print(f\"   📄 상위 결과: {filtered_docs[0].page_content[:80]}...\")\n",
    "                else:\n",
    "                    print(\"   ❌ 임계값 조건을 만족하는 문서 없음\")\n",
    "            else:\n",
    "                print(\"   ❌ 필터 생성 실패\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ 오류 발생: {e}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # 결과 시각화\n",
    "    if threshold_results:\n",
    "        print(\"\\n📊 임계값별 결과 요약:\")\n",
    "        \n",
    "        # DataFrame 생성\n",
    "        df = pd.DataFrame(threshold_results).T\n",
    "        df.index.name = 'Threshold'\n",
    "        df = df.round(3)\n",
    "        print(df.to_string())\n",
    "        \n",
    "        # 시각화\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        # 필터링된 문서 수\n",
    "        ax1.bar(df.index, df['filtered_count'], color='skyblue')\n",
    "        ax1.set_title('임계값별 필터링된 문서 수')\n",
    "        ax1.set_xlabel('유사도 임계값')\n",
    "        ax1.set_ylabel('문서 수')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 처리 시간\n",
    "        ax2.bar(df.index, df['processing_time'], color='lightcoral')\n",
    "        ax2.set_title('임계값별 처리 시간')\n",
    "        ax2.set_xlabel('유사도 임계값')\n",
    "        ax2.set_ylabel('처리 시간 (초)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return threshold_results\n",
    "\n",
    "# 임베딩 필터 임계값 테스트\n",
    "threshold_test_results = test_embeddings_filter_thresholds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 포괄적인 문서 압축 파이프라인 생성 (비쌈)\n",
    "\n",
    "\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "\n",
    "\n",
    "def create_comprehensive_pipeline():\n",
    "    \"\"\"\n",
    "    포괄적인 문서 압축 파이프라인 생성\n",
    "    \n",
    "    Returns:\n",
    "        ContextualCompressionRetriever: 다단계 압축 검색기\n",
    "    \"\"\"\n",
    "    print(\"🔧 포괄적인 문서 압축 파이프라인 구성\")\n",
    "    \n",
    "    try:\n",
    "        # 임베딩 모델 초기화\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        \n",
    "        # LLM 초기화\n",
    "        llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "        \n",
    "        # 파이프라인 구성 요소들\n",
    "        print(\"   1️⃣ 중복 제거 필터 추가\")\n",
    "        redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "        \n",
    "        print(\"   2️⃣ 유사도 기반 필터 추가 (임계값: 0.4)\")\n",
    "        similarity_filter = EmbeddingsFilter(\n",
    "            embeddings=embeddings, \n",
    "            similarity_threshold=0.4\n",
    "        )\n",
    "        \n",
    "        print(\"   3️⃣ LLM 기반 재순위화 추가\")\n",
    "        llm_reranker = LLMListwiseRerank.from_llm(llm, top_n=5)\n",
    "        \n",
    "        # 파이프라인 생성\n",
    "        pipeline_compressor = DocumentCompressorPipeline(\n",
    "            transformers=[\n",
    "                redundant_filter,    # 1단계: 중복 제거\n",
    "                similarity_filter,   # 2단계: 유사도 필터링\n",
    "                llm_reranker        # 3단계: LLM 재순위화\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # 최종 압축 검색기 생성\n",
    "        pipeline_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=pipeline_compressor,\n",
    "            base_retriever=base_retriever,\n",
    "        )\n",
    "        \n",
    "        print(\"✅ 포괄적인 압축 파이프라인 생성 완료\")\n",
    "        return pipeline_retriever\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 파이프라인 생성 실패: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "# 파이프라인 생성\n",
    "pipeline_retriever = create_comprehensive_pipeline()\n",
    "\n",
    "# 파이프라인 검색기 사용하여 검색\n",
    "query = \"테슬라 트럭 모델이 있나요?\"\n",
    "retrieved_docs = pipeline_retriever.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "print(\"\\n🔄 포괄적인 문서 압축 파이프라인 검색 결과:\")\n",
    "print(f\"   필터링된 문서 수: {len(retrieved_docs)}개\")\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"{doc.page_content} [출처: {doc.metadata['source']}]\")\n",
    "    print(\"=\"*200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ranx-k 라이브러리 사용해서 검색 결과 평가\n",
    "\n",
    "\n",
    "ranx-k 평가 실행 (rouge 점수가 높은 경우) -> 문자열 유사도 기반 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 각 평가 비교 #####\n",
    "# base retriever 평가\n",
    "base_results = evaluate_with_ranx_similarity(\n",
    "    retriever=base_retriever,\n",
    "    questions=questions, \n",
    "    reference_contexts=reference_contexts,\n",
    "    k=5,\n",
    "    method='kiwi_rouge',  \n",
    "    similarity_threshold=0.8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-encoder 재순위화 평가\n",
    "rerank_results = evaluate_with_ranx_similarity(\n",
    "    retriever=cross_encoder_retriever,\n",
    "    questions=questions, \n",
    "    reference_contexts=reference_contexts,\n",
    "    k=5,\n",
    "    method='kiwi_rouge',  \n",
    "    similarity_threshold=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
