{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LangChainì˜ ê°œë…ê³¼ ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ì´í•´\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LangChain ì†Œê°œ\n",
    "\n",
    "### 1.1 LangChainì´ë€?\n",
    "**LangChain**ì€ ëŒ€í™”í˜• AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ“¦ í•µì‹¬ ê°€ì¹˜\n",
    "- **ëª¨ë“ˆí™”**: ë…ë¦½ì ì¸ ì»´í¬ë„ŒíŠ¸ë¥¼ ì¡°í•©í•˜ì—¬ ë³µì¡í•œ AI ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "- **ìƒí˜¸ìš´ìš©ì„±**: ë‹¤ì–‘í•œ AI ëª¨ë¸ê³¼ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í•˜ë‚˜ì˜ ì¸í„°í˜ì´ìŠ¤ë¡œ í†µí•©\n",
    "- **í™•ì¥ì„±**: ê°„ë‹¨í•œ ì±—ë´‡ë¶€í„° ë³µì¡í•œ AI ì—ì´ì „íŠ¸ê¹Œì§€ í™•ì¥ ê°€ëŠ¥\n",
    "- **ê´€ì°°ì„±**: LangSmithë¥¼ í†µí•œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…\n",
    "\n",
    "#### ğŸ“¦ í•µì‹¬ ì•„í‚¤í…ì²˜\n",
    "```markdown\n",
    "**LangChain ìƒíƒœê³„**\n",
    "â”œâ”€â”€ langchain-core     # ê¸°ë³¸ ì¶”ìƒí™” ë° ì¸í„°í˜ì´ìŠ¤\n",
    "â”œâ”€â”€ langchain         # ì²´ì¸, ì—ì´ì „íŠ¸, ê²€ìƒ‰ ì „ëµ\n",
    "â”œâ”€â”€ langchain-openai  # OpenAI í†µí•©\n",
    "â”œâ”€â”€ langchain-anthropic # Anthropic í†µí•©\n",
    "â”œâ”€â”€ LangGraph        # ë³µì¡í•œ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°\n",
    "â””â”€â”€ LangSmith        # ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://python.langchain.com/svg/langchain_stack_112024_dark.svg\" \n",
    "        alt=\"langchain_stack\" \n",
    "        width=\"600\" \n",
    "        style=\"border: 0;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "### 2.1 ì„¤ì¹˜\n",
    "\n",
    "```bash\n",
    "# pip ì„¤ì¹˜\n",
    "pip install langchain langchain-openai langchain-google-genai\n",
    "\n",
    "# uv ì„¤ì¹˜ \n",
    "uv add langchain langchain-openai langchain-google-genai\n",
    "\n",
    "# ì¶”ê°€ ë„êµ¬ pip ì„¤ì¹˜ (ì„ íƒì‚¬í•­)\n",
    "pip install langchain-ollama langsmith\n",
    "\n",
    "# ì¶”ê°€ ë„êµ¬ uv ì„¤ì¹˜ (ì„ íƒì‚¬í•­)\n",
    "uv add langchain-ollama langsmith\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 API í‚¤ ì„¤ì •\n",
    "```python\n",
    "# .env íŒŒì¼ ìƒì„±\n",
    "OPENAI_API_KEY=your_openai_api_key_here\n",
    "GOOGLE_API_KEY=your_google_api_key_here\n",
    "\n",
    "# LangSmith ì„¤ì • (ì„ íƒì‚¬í•­)\n",
    "LANGSMITH_API_KEY=your_langsmith_api_key\n",
    "LANGSMITH_TRACING=true\n",
    "LANGSMITH_PROJECT=your_project_name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì : None\n"
     ]
    }
   ],
   "source": [
    "# LangSmith ì¶”ì  í™•ì¸\n",
    "import os\n",
    "print(f\"LangSmith ì¶”ì : {os.getenv('LANGSMITH_TRACING')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. í•µì‹¬ ì»´í¬ë„ŒíŠ¸\n",
    "\n",
    "### 3.1 Chat Models (ì±„íŒ… ëª¨ë¸)\n",
    "\n",
    "- OpenAI, Anthropic, Google ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì„ ì§€ì›\n",
    "- í…ìŠ¤íŠ¸ ìƒì„±, ëŒ€í™”, ìš”ì•½ ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€: íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.\n",
      "ë©”íƒ€ë°ì´í„°: {'token_usage': {'completion_tokens': 11, 'prompt_tokens': 18, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_6d7dcc9a98', 'id': 'chatcmpl-CDLsgnegzj5cfeMphOH3XAiWi5eAQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\", \n",
    "    temperature=0.3,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "# ê°„ë‹¨í•œ ëŒ€í™”\n",
    "response = model.invoke(\"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "print(f\"ë‹µë³€: {response.content}\")\n",
    "print(f\"ë©”íƒ€ë°ì´í„°: {response.response_metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Messages (ë©”ì‹œì§€)\n",
    "\n",
    "- ë©”ì‹œì§€ëŠ” AIì™€ì˜ ëŒ€í™”ì—ì„œ ì—­í• ì„ êµ¬ë¶„í•˜ëŠ” ê¸°ë³¸ ë‹¨ìœ„ì…ë‹ˆë‹¤.\n",
    "- ë©”ì‹œì§€ëŠ” ì‚¬ìš©ì, AI, ì‹œìŠ¤í…œ ë“± ë‹¤ì–‘í•œ ì—­í• ì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë©”ì‹œì§€: AIì˜ ì—­í•  ì •ì˜\n",
    "system_msg = SystemMessage(content=\"ë‹¹ì‹ ì€ ëŒ€í•™êµ êµìˆ˜, ì¶”ê°€ì ì¸ ë¶€ê°€ì„¤ëª…ê¹Œì§€ í•´ì£¼ëŠ” í™”í•™ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "# ì‚¬ìš©ì ë©”ì‹œì§€\n",
    "human_msg = HumanMessage(content=\"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ëª‡ ë²ˆì¸ê°€ìš”?\")\n",
    "\n",
    "# ëŒ€í™” ì‹¤í–‰\n",
    "messages = [system_msg, human_msg]\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ë²ˆì…ë‹ˆë‹¤.\n",
      "\n",
      "ì›ì ë²ˆí˜¸ëŠ” ì›ìí•µ ë‚´ì— ìˆëŠ” ì–‘ì„±ìì˜ ìˆ˜ë¥¼ ì˜ë¯¸í•˜ëŠ”ë°, íƒ„ì†ŒëŠ” 6ê°œì˜ ì–‘ì„±ìë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ ìˆ«ìëŠ” ì›ì†Œì˜ í™”í•™ì  ì„±ì§ˆì„ ê²°ì •í•˜ëŠ” ì¤‘ìš”í•œ ê°’ìœ¼ë¡œ, ì£¼ê¸°ìœ¨í‘œì—ì„œ íƒ„ì†ŒëŠ” 6ë²ˆì§¸ ì›ì†Œë¡œ ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤. íƒ„ì†ŒëŠ” 4ê°œì˜ ì›ìê°€ ì „ìë¥¼ ê°€ì§€ê³  ìˆì–´ ë‹¤ì–‘í•œ í™”í•©ë¬¼ì„ í˜•ì„±í•  ìˆ˜ ìˆëŠ”ë°, ì´ëŠ” ìœ ê¸°í™”í•™ì˜ ê¸°ë³¸ì´ ë˜ëŠ” ì´ìœ  ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'finish_reason': 'stop',\n",
      " 'id': 'chatcmpl-CDLwOKAwfCRb1DWtRfo20n4x4qjbN',\n",
      " 'logprobs': None,\n",
      " 'model_name': 'gpt-4.1-mini-2025-04-14',\n",
      " 'service_tier': 'default',\n",
      " 'system_fingerprint': 'fp_4fce0778af',\n",
      " 'token_usage': {'completion_tokens': 116,\n",
      "                 'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
      "                                               'audio_tokens': 0,\n",
      "                                               'reasoning_tokens': 0,\n",
      "                                               'rejected_prediction_tokens': 0},\n",
      "                 'prompt_tokens': 46,\n",
      "                 'prompt_tokens_details': {'audio_tokens': 0,\n",
      "                                           'cached_tokens': 0},\n",
      "                 'total_tokens': 162}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Prompt Templates (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿)\n",
    "\n",
    "- í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ë³€ìˆ˜ ì¹˜í™˜ì„ í†µí•´ ë™ì ì¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì ìš©í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ“¦ ê¸°ë³¸ í…œí”Œë¦¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•„ìˆ˜ ë³€ìˆ˜: ['question', 'topic']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# ì „ë¬¸ê°€ í…œí”Œë¦¿\n",
    "template = \"\"\"\n",
    "ë‹¹ì‹ ì€ {topic} ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {topic}ì— ê´€í•œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "ì§ˆë¬¸: {question}\n",
    "ë‹µë³€: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# í…œí”Œë¦¿ ì…ë ¥ ë³€ìˆ˜ í™•ì¸\n",
    "print(f\"í•„ìˆ˜ ë³€ìˆ˜: {prompt.input_variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…œí”Œë¦¿: \n",
      "ë‹¹ì‹ ì€ {topic} ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {topic}ì— ê´€í•œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
      "ì§ˆë¬¸: {question}\n",
      "ë‹µë³€: \n"
     ]
    }
   ],
   "source": [
    "# í…œí”Œë¦¿ í™•ì¸\n",
    "print(f\"í…œí”Œë¦¿: {prompt.template}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ë‹¹ì‹ ì€ í™”í•™ ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í™”í•™ì— ê´€í•œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
      "ì§ˆë¬¸: íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "ë‹µë³€: \n"
     ]
    }
   ],
   "source": [
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "formatted_prompt = prompt.format(\n",
    "    topic=\"í™”í•™\",\n",
    "    question=\"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    ")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ“¦ ì±„íŒ… í…œí”Œë¦¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# ì±„íŒ…ìš© í…œí”Œë¦¿\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì „ë¬¸ {subject} ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# í…œí”Œë¦¿ ì‚¬ìš©\n",
    "prompt = chat_template.invoke({\n",
    "    \"subject\": \"ì§„ë¡œ\",\n",
    "    \"question\": \"ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ê°€ ë˜ë ¤ë©´ ì–´ë–¤ ê³µë¶€ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatPromptValue(messages=[SystemMessage(content='ë‹¹ì‹ ì€ ì „ë¬¸ ì§„ë¡œ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ê°€ ë˜ë ¤ë©´ ì–´ë–¤ ê³µë¶€ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?', additional_kwargs={}, response_metadata={})])\n"
     ]
    }
   ],
   "source": [
    "# í…œí”Œë¦¿ í™•ì¸\n",
    "pprint(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='ë‹¹ì‹ ì€ ì „ë¬¸ ì§„ë¡œ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ê°€ ë˜ë ¤ë©´ ì–´ë–¤ ê³µë¶€ë¥¼ í•´ì•¼ í•˜ë‚˜ìš”?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# ë©”ì‹œì§€ ì†ì„± í™•ì¸\n",
    "pprint(prompt.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. LCEL (LangChain Expression Language)\n",
    "\n",
    "### 4.1 LCELì´ë€?\n",
    "**LCEL**ì€ `|` ì—°ì‚°ìë¥¼ ì‚¬ìš©í•˜ì—¬ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•˜ëŠ” ì„ ì–¸ì  ì²´ì´ë‹ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ“¦ í•µì‹¬ íŠ¹ì§•\n",
    "- **ì¬ì‚¬ìš©ì„±**: ì •ì˜ëœ ì²´ì¸ì„ ë‹¤ë¥¸ ì²´ì¸ì˜ ì»´í¬ë„ŒíŠ¸ë¡œ í™œìš©\n",
    "- **ë‹¤ì–‘í•œ ì‹¤í–‰ ë°©ì‹**: `.invoke()`, `.batch()`, `.stream()`, `.astream()`\n",
    "- **ìë™ ìµœì í™”**: ë°°ì¹˜ ì²˜ë¦¬ ì‹œ íš¨ìœ¨ì ì¸ ì‘ì—… ìˆ˜í–‰\n",
    "- **ìŠ¤í‚¤ë§ˆ ì§€ì›**: ì…ë ¥/ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ìë™ ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ê¸°ë³¸ ì²´ì¸ êµ¬ì„±\n",
    "\n",
    "#### ğŸ“¦ Prompt + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€: íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.\n",
      "ë‹µë³€: content='íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 46, 'total_tokens': 57, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4fce0778af', 'id': 'chatcmpl-CDNbBWRtR4SC0Txv7eytEaHJImrYg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--af237063-9f79-4609-b669-6ebea9c7738a-0' usage_metadata={'input_tokens': 46, 'output_tokens': 11, 'total_tokens': 57, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì»´í¬ë„ŒíŠ¸ ì •ì˜\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"ë‹¹ì‹ ì€ {topic} ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {topic}ì— ê´€í•œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\\n\"\n",
    "    \"ì§ˆë¬¸: {question}\\në‹µë³€: \"\n",
    ")\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.3)\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | llm\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "response = chain.invoke({\n",
    "    \"topic\": \"í™”í•™\",\n",
    "    \"question\": \"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "})\n",
    "\n",
    "print(f\"ë‹µë³€: {response.content}\")\n",
    "print(f\"ë‹µë³€: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ“¦ Prompt + LLM + Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€: ë‹µë³€: íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.\n",
      "output_parser: <class 'langchain_core.output_parsers.string.StrOutputParser'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ì¶œë ¥ íŒŒì„œ ì¶”ê°€\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# ì™„ì „í•œ ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ (ë¬¸ìì—´ ë°˜í™˜)\n",
    "response = chain.invoke({\n",
    "    \"topic\": \"í™”í•™\",\n",
    "    \"question\": \"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "})\n",
    "\n",
    "print(f\"ë‹µë³€: {response}\")  # ì´ì œ ë¬¸ìì—´ë¡œ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. LangSmith ëª¨ë‹ˆí„°ë§\n",
    "\n",
    "### 5.1 LangSmithë€?\n",
    "**LangSmith**ëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê´€ì°°ì„±(Observability)ì„ ì œê³µí•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ“¦ ì£¼ìš” ê¸°ëŠ¥\n",
    "- **ì²´ì¸ ì‹¤í–‰ ë¡œê¹… ë° ì¶”ì **\n",
    "- **í”„ë¡¬í”„íŠ¸ ë””ë²„ê¹…**\n",
    "- **ì„±ëŠ¥ ì¸¡ì • ë° ë¶„ì„**\n",
    "- **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**\n",
    "\n",
    "### 5.2 LangSmith ì„¤ì •\n",
    "\n",
    "#### ğŸ“¦ ê³„ì • ê°€ì… ë° ì„¤ì •\n",
    "```python\n",
    "# 1. LangSmith ê³„ì • ê°€ì…: https://www.langchain.com/langsmith\n",
    "# 2. .env íŒŒì¼ ì„¤ì •\n",
    "LANGSMITH_API_KEY=your_langsmith_api_key\n",
    "LANGSMITH_TRACING=true\n",
    "LANGSMITH_PROJECT=your_project_name\n",
    "\n",
    "# 3. í™˜ê²½ í™•ì¸\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(f\"LangSmith ì¶”ì  ìƒíƒœ: {os.getenv('LANGSMITH_TRACING')}\")\n",
    "print(f\"í”„ë¡œì íŠ¸ëª…: {os.getenv('LANGSMITH_PROJECT')}\")\n",
    "```\n",
    "\n",
    "### 5.3 ìë™ ì¶”ì \n",
    "\n",
    "LangSmithê°€ ì„¤ì •ë˜ë©´ ëª¨ë“  ì²´ì¸ ì‹¤í–‰ì´ ìë™ìœ¼ë¡œ ì¶”ì ë©ë‹ˆë‹¤:\n",
    "\n",
    "```python\n",
    "# ì²´ì¸ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ LangSmithì— ë¡œê·¸ ì „ì†¡\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"topic\": \"ì¸ê³µì§€ëŠ¥\",\n",
    "    \"question\": \"ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì€?\"\n",
    "})\n",
    "\n",
    "# LangSmith ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤í–‰ ê³¼ì • í™•ì¸ ê°€ëŠ¥:\n",
    "# - ê° ë‹¨ê³„ë³„ ì‹¤í–‰ ì‹œê°„\n",
    "# - ì…ë ¥/ì¶œë ¥ ë°ì´í„°\n",
    "# - í† í° ì‚¬ìš©ëŸ‰\n",
    "# - ì—ëŸ¬ ì¶”ì \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì  ìƒíƒœ: true\n",
      "í”„ë¡œì íŠ¸ëª…: ktds-llm-20250908\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. í™˜ê²½ í™•ì¸\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(f\"LangSmith ì¶”ì  ìƒíƒœ: {os.getenv('LANGSMITH_TRACING')}\")\n",
    "print(f\"í”„ë¡œì íŠ¸ëª…: {os.getenv('LANGSMITH_PROJECT')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ LangSmithì— ë¡œê·¸ ì „ì†¡\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"topic\": \"ì¸ê³µì§€ëŠ¥\",\n",
    "    \"question\": \"ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì€?\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Runnable ì¸í„°í˜ì´ìŠ¤\n",
    "\n",
    "### 6.1 Runnable ê°œë…\n",
    "ëª¨ë“  LangChain ì»´í¬ë„ŒíŠ¸ëŠ” **Runnable ì¸í„°í˜ì´ìŠ¤**ë¥¼ êµ¬í˜„í•˜ì—¬ ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ“¦ ì£¼ìš” Runnable ìœ í˜•\n",
    "- `RunnableSequence`: ìˆœì°¨ì  ì‹¤í–‰\n",
    "- `RunnableParallel`: ë³‘ë ¬ ì‹¤í–‰\n",
    "- `RunnablePassthrough`: ì…ë ¥ ì „ë‹¬\n",
    "- `RunnableLambda`: í•¨ìˆ˜ ë˜í•‘\n",
    "\n",
    "### 6.2 RunnableSequence (ìˆœì°¨ ì‹¤í–‰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have a nice day!\n"
     ]
    }
   ],
   "source": [
    "# ë²ˆì—­ ì „ìš© ì²´ì¸ (íŒŒì´í”„ ì—°ì‚°ì ì‚¬ìš©)\n",
    "translation_prompt = PromptTemplate.from_template(\n",
    "    \"'{text}'ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ëœ ë¬¸ì¥ë§Œì„ ì¶œë ¥í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "translation_chain = translation_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ë²ˆì—­ ì‹¤í–‰\n",
    "result = translation_chain.invoke({\"text\": \"ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have a nice day!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "# ëª…ì‹œì  RunnableSequence ìƒì„±\n",
    "translation_chain = RunnableSequence(\n",
    "    first=translation_prompt, \n",
    "    middle=[llm],\n",
    "    last=StrOutputParser()\n",
    ")\n",
    "\n",
    "# íŒŒì´í”„ ì—°ì‚°ìì™€ ë™ì¼í•œ ê²°ê³¼\n",
    "# translation_chain = translation_prompt | llm | StrOutputParser()\n",
    "\n",
    "result = translation_chain.invoke({\"text\": \"ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”!\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 RunnableParallel (ë³‘ë ¬ ì‹¤í–‰)\n",
    "\n",
    "#### ğŸ“¦ ì§ˆë¬¸ ë¶„ì„ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì£¼ì œ ë¶„ë¥˜: í™”í•™(Chemistry)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter\n",
    "\n",
    "# 1. ì£¼ì œ ë¶„ë¥˜ ì²´ì¸\n",
    "topic_template = \"\"\"\n",
    "ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:\n",
    "- í™”í•™(Chemistry)\n",
    "- ë¬¼ë¦¬(Physics)  \n",
    "- ìƒë¬¼(Biology)\n",
    "\n",
    "ìœ„ 3ê°€ì§€ ì¹´í…Œê³ ë¦¬ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\"\"\"\n",
    "\n",
    "topic_prompt = PromptTemplate.from_template(topic_template)\n",
    "topic_chain = topic_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = topic_chain.invoke({\n",
    "    \"question\": \"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "})\n",
    "print(f\"ì£¼ì œ ë¶„ë¥˜: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì–¸ì–´ ë¶„ë¥˜: ì˜ì–´(English)\n"
     ]
    }
   ],
   "source": [
    "# 2. ì–¸ì–´ ê°ì§€ ì²´ì¸\n",
    "language_template = \"\"\"\n",
    "ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”:\n",
    "- í•œêµ­ì–´(Korean)\n",
    "- ì˜ì–´(English)\n",
    "- ê¸°íƒ€(Others)\n",
    "\n",
    "ìœ„ 3ê°€ì§€ ì¹´í…Œê³ ë¦¬ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "\n",
    "ì…ë ¥: {question}\n",
    "\"\"\"\n",
    "\n",
    "language_prompt = PromptTemplate.from_template(language_template)\n",
    "language_chain = language_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = language_chain.invoke({\n",
    "    \"question\": \"What is the atomic number of Carbon?\"\n",
    "})\n",
    "print(f\"ì–¸ì–´ ë¶„ë¥˜: {result}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì¢… ë‹µë³€: ë‹µë³€: íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” 6ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# 3. ë‹µë³€ ìƒì„± ì²´ì¸\n",
    "answer_template = \"\"\"\n",
    "ë‹¹ì‹ ì€ {topic} ë¶„ì•¼ì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. \n",
    "{language}ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "ë‹µë³€: \"\"\"\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(answer_template)\n",
    "\n",
    "# 4. ë³‘ë ¬ ì²˜ë¦¬ ì²´ì¸ êµ¬ì„±\n",
    "analysis_chain = RunnableParallel({\n",
    "    \"topic\": topic_chain,\n",
    "    \"language\": language_chain,\n",
    "    \"question\": itemgetter(\"question\")\n",
    "})\n",
    "\n",
    "# 5. ì „ì²´ ì²´ì¸ ì—°ê²°\n",
    "complete_chain = analysis_chain | answer_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = complete_chain.invoke({\n",
    "    \"question\": \"íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "})\n",
    "print(f\"ìµœì¢… ë‹µë³€: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. ê°ì • ë¶„ì„ íŒŒì´í”„ë¼ì¸ (ì˜ˆì œ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìš”ì•½: ì˜¤ëŠ˜ ì‹œí—˜ì„ ì—´ì‹¬íˆ ê³µë¶€í•œ ë•ë¶„ì— ì˜ ë´¤ê³ , ì¢‹ì€ ê²°ê³¼ë¥¼ ê¸°ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "ê°ì • ë¶„ì„: ê¸ì •\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
    "\n",
    "# ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "summarize_prompt = PromptTemplate.from_template(\n",
    "    \"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”: {text}\"\n",
    ")\n",
    "\n",
    "# ê°ì • ë¶„ì„ í”„ë¡¬í”„íŠ¸\n",
    "sentiment_prompt = PromptTemplate.from_template(\"\"\"\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "í…ìŠ¤íŠ¸: {summary}\n",
    "\n",
    "ê·œì¹™:\n",
    "1. ë°˜ë“œì‹œ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”\n",
    "2. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\n",
    "\"\"\")\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±\n",
    "summarize_chain = summarize_prompt | llm\n",
    "sentiment_chain = sentiment_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ì „ì²´ íŒŒì´í”„ë¼ì¸\n",
    "analysis_pipeline = (\n",
    "    summarize_chain \n",
    "    | RunnableParallel(\n",
    "        summary=lambda x: x.content,\n",
    "        sentiment=lambda x: sentiment_chain.invoke({\"summary\": x.content}),\n",
    "    )\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸\n",
    "text = \"\"\"ì˜¤ëŠ˜ ì‹œí—˜ì„ ë´¤ëŠ”ë° ì •ë§ ì˜ ë³¸ ê²ƒ ê°™ì•„ìš”. \n",
    "ëª‡ ì£¼ ë™ì•ˆ ì—´ì‹¬íˆ ê³µë¶€í•œ ë³´ëŒì´ ìˆë„¤ìš”. \n",
    "ê²°ê³¼ê°€ ë‚˜ì˜¤ë©´ ì¢‹ì€ ì ìˆ˜ë¥¼ ë°›ì„ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ì„œ ê¸°ëŒ€ë©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "result = analysis_pipeline.invoke({\"text\": text})\n",
    "print(f\"ìš”ì•½: {result['summary']}\")\n",
    "print(f\"ê°ì • ë¶„ì„: {result['sentiment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. ì‹¤ìŠµ ë¬¸ì œ\n",
    "\n",
    "#### ğŸŒŸ ë¬¸ì œ 1: LCEL ê¸°ë³¸ ì²´ì¸ ë§Œë“¤ê¸°\n",
    "- ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì£¼ì œì— ëŒ€í•´ 3ì¤„ ìš”ì•½ ì œê³µ\n",
    "- ì˜¨ë„ëŠ” 0.5ë¡œ ì„¤ì •\n",
    "- ë¬¸ìì—´ ì¶œë ¥ íŒŒì„œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìš”ì•½: ì˜¤ëŠ˜ ì‹œí—˜ì„ ì—´ì‹¬íˆ ê³µë¶€í•œ ë³´ëŒìœ¼ë¡œ ì˜ ë³¸ ê²ƒ ê°™ì•„ìš”.  \n",
      "ê²°ê³¼ê°€ ì¢‹ì„ ê²ƒ ê°™ì•„ ê¸°ëŒ€ë©ë‹ˆë‹¤.  \n",
      "ë‹¤ìŒ ì‹œí—˜ë„ ì—´ì‹¬íˆ ì¤€ë¹„í•  ê³„íšì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "# ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "summarize_prompt = PromptTemplate.from_template(\n",
    "    \"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”: {text}\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.5)\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±\n",
    "summarize_chain = summarize_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸\n",
    "text = \"\"\"ì˜¤ëŠ˜ ì‹œí—˜ì„ ë´¤ëŠ”ë° ì •ë§ ì˜ ë³¸ ê²ƒ ê°™ì•„ìš”. \n",
    "ëª‡ ì£¼ ë™ì•ˆ ì—´ì‹¬íˆ ê³µë¶€í•œ ë³´ëŒì´ ìˆë„¤ìš”. \n",
    "ê²°ê³¼ê°€ ë‚˜ì˜¤ë©´ ì¢‹ì€ ì ìˆ˜ë¥¼ ë°›ì„ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ì„œ ê¸°ëŒ€ë©ë‹ˆë‹¤. ë‹¤ìŒì‹œí—˜ã…‡ë„ ì—´ì‹¬íˆ ì¤€ë¹„í•´ì•¼ê² ì–´ìš”.\"\"\"\n",
    "\n",
    "result = summarize_chain.invoke({\"text\": text})\n",
    "print(f\"ìš”ì•½: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸŒŸ ë¬¸ì œ 2: RunnableParallel í™œìš©\n",
    "- í•˜ë‚˜ì˜ ì…ë ¥ì— ëŒ€í•´ ë²ˆì—­ê³¼ ìš”ì•½ì„ ë™ì‹œì— ìˆ˜í–‰í•˜ëŠ” ì²´ì¸ì„ ë§Œë“œì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to PromptTemplate is missing variables {'text'}.  Expected: ['text'] Received: ['ì˜¤ëŠ˜ ì‹œí—˜ì„ ë´¤ëŠ”ë° ì •ë§ ì˜ ë³¸ ê²ƒ ê°™ì•„ìš”. \\\\nëª‡ ì£¼ ë™ì•ˆ ì—´ì‹¬íˆ ê³µë¶€í•œ ë³´ëŒì´ ìˆë„¤ìš”. \\\\nê²°ê³¼ê°€ ë‚˜ì˜¤ë©´ ì¢‹ì€ ì ìˆ˜ë¥¼ ë°›ì„ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ì„œ ê¸°ëŒ€ë©ë‹ˆë‹¤.']\\nNote: if you intended {text} to be part of the string and not a variable, please escape it with double curly braces like: '{{text}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     39\u001b[39m text = \u001b[33m\"\"\"\u001b[39m\u001b[33mì˜¤ëŠ˜ ì‹œí—˜ì„ ë´¤ëŠ”ë° ì •ë§ ì˜ ë³¸ ê²ƒ ê°™ì•„ìš”. \u001b[39m\n\u001b[32m     40\u001b[39m \u001b[33mëª‡ ì£¼ ë™ì•ˆ ì—´ì‹¬íˆ ê³µë¶€í•œ ë³´ëŒì´ ìˆë„¤ìš”. \u001b[39m\n\u001b[32m     41\u001b[39m \u001b[33mê²°ê³¼ê°€ ë‚˜ì˜¤ë©´ ì¢‹ì€ ì ìˆ˜ë¥¼ ë°›ì„ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ì„œ ê¸°ëŒ€ë©ë‹ˆë‹¤.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# ì‹¤í–‰\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m result = \u001b[43mcomplete_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mìµœì¢… ë‹µë³€: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m\"\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ys\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3080\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3079\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3080\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3081\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3082\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ys\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3816\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3811\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3812\u001b[39m         futures = [\n\u001b[32m   3813\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3814\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3815\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m3816\u001b[39m         output = {key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[32m   3817\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3818\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\concurrent\\futures\\_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.11-windows-x86_64-none\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ys\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3800\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input_, config, key)\u001b[39m\n\u001b[32m   3794\u001b[39m child_config = patch_config(\n\u001b[32m   3795\u001b[39m     config,\n\u001b[32m   3796\u001b[39m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[32m   3797\u001b[39m     callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   3798\u001b[39m )\n\u001b[32m   3799\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m-> \u001b[39m\u001b[32m3800\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3801\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3802\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3803\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3804\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ys\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3080\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3079\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3080\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3081\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3082\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ys\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:216\u001b[39m, in \u001b[36mBasePromptTemplate.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tags:\n\u001b[32m    215\u001b[39m     config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] = config[\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[38;5;28mself\u001b[39m.tags\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_prompt_with_error_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserialized\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ys\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1953\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1949\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1950\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1951\u001b[39m         output = cast(\n\u001b[32m   1952\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1953\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1955\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1956\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1957\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1958\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1959\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1961\u001b[39m         )\n\u001b[32m   1962\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1963\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ys\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:429\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    428\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ys\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:189\u001b[39m, in \u001b[36mBasePromptTemplate._format_prompt_with_error_handling\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) -> PromptValue:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     inner_input_ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_prompt(**inner_input_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ys\\ktds-llm\\.venv\\Lib\\site-packages\\langchain_core\\prompts\\base.py:183\u001b[39m, in \u001b[36mBasePromptTemplate._validate_input\u001b[39m\u001b[34m(self, inner_input)\u001b[39m\n\u001b[32m    177\u001b[39m     example_key = missing.pop()\n\u001b[32m    178\u001b[39m     msg += (\n\u001b[32m    179\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m to be part of the string\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    182\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    184\u001b[39m         create_message(message=msg, error_code=ErrorCode.INVALID_PROMPT_INPUT)\n\u001b[32m    185\u001b[39m     )\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[31mKeyError\u001b[39m: \"Input to PromptTemplate is missing variables {'text'}.  Expected: ['text'] Received: ['ì˜¤ëŠ˜ ì‹œí—˜ì„ ë´¤ëŠ”ë° ì •ë§ ì˜ ë³¸ ê²ƒ ê°™ì•„ìš”. \\\\nëª‡ ì£¼ ë™ì•ˆ ì—´ì‹¬íˆ ê³µë¶€í•œ ë³´ëŒì´ ìˆë„¤ìš”. \\\\nê²°ê³¼ê°€ ë‚˜ì˜¤ë©´ ì¢‹ì€ ì ìˆ˜ë¥¼ ë°›ì„ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ì„œ ê¸°ëŒ€ë©ë‹ˆë‹¤.']\\nNote: if you intended {text} to be part of the string and not a variable, please escape it with double curly braces like: '{{text}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# ìš”ì•½ í”„ë¡¬í”„íŠ¸\n",
    "summarize_prompt = PromptTemplate.from_template(\n",
    "    \"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”: {text}\"\n",
    ")\n",
    "\n",
    "# ë²ˆì—­ í”„ë¡¬í”„íŠ¸\n",
    "translation_prompt = PromptTemplate.from_template(\"\"\"\n",
    "ì…ë ¥ì–¸ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.  í…ìŠ¤íŠ¸: {text}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(answer_template)\n",
    "\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±\n",
    "summarize_chain = summarize_prompt | llm | StrOutputParser()\n",
    "translation_chain = translation_prompt | llm | StrOutputParser()\n",
    "\n",
    "# ë³‘ë ¬ ì²˜ë¦¬ ì²´ì¸ êµ¬ì„±\n",
    "analysis_chain =  RunnableParallel({\n",
    "\n",
    "      \"summary\": summarize_chain,\n",
    "        \"translation\": translation_chain,\n",
    "\n",
    "        # summary=lambda x: summarize_chain.invoke({\"text\": text})\n",
    "        # sentiment=lambda x: sentiment_chain.invoke({\"summary\": x.content}),\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5. ì „ì²´ ì²´ì¸ ì—°ê²°\n",
    "complete_chain = analysis_chain  | llm | StrOutputParser()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸\n",
    "text = \"\"\"ì˜¤ëŠ˜ ì‹œí—˜ì„ ë´¤ëŠ”ë° ì •ë§ ì˜ ë³¸ ê²ƒ ê°™ì•„ìš”. \n",
    "ëª‡ ì£¼ ë™ì•ˆ ì—´ì‹¬íˆ ê³µë¶€í•œ ë³´ëŒì´ ìˆë„¤ìš”. \n",
    "ê²°ê³¼ê°€ ë‚˜ì˜¤ë©´ ì¢‹ì€ ì ìˆ˜ë¥¼ ë°›ì„ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ì„œ ê¸°ëŒ€ë©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "# ì‹¤í–‰\n",
    "result = complete_chain.invoke({text: text})\n",
    "\n",
    "print(f\"ìµœì¢… ë‹µë³€: {result[\"summary\"]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— ìœ ìš©í•œ ë§í¬\n",
    "\n",
    "- [LangChain ê³µì‹ ë¬¸ì„œ](https://python.langchain.com/docs/introduction/)\n",
    "- [LangSmith ê°€ì´ë“œ](https://docs.smith.langchain.com/)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
